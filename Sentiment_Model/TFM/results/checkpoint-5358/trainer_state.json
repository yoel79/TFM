{
  "best_metric": 0.23093931376934052,
  "best_model_checkpoint": "./results\\checkpoint-5358",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 5358,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.005599104143337066,
      "grad_norm": 1.6403542757034302,
      "learning_rate": 4.0000000000000003e-07,
      "loss": 1.1087,
      "step": 10
    },
    {
      "epoch": 0.011198208286674132,
      "grad_norm": 1.1767473220825195,
      "learning_rate": 8.000000000000001e-07,
      "loss": 1.1035,
      "step": 20
    },
    {
      "epoch": 0.0167973124300112,
      "grad_norm": 0.9449052810668945,
      "learning_rate": 1.2000000000000002e-06,
      "loss": 1.1026,
      "step": 30
    },
    {
      "epoch": 0.022396416573348264,
      "grad_norm": 1.1703259944915771,
      "learning_rate": 1.6000000000000001e-06,
      "loss": 1.0956,
      "step": 40
    },
    {
      "epoch": 0.027995520716685332,
      "grad_norm": 1.0872222185134888,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 1.0997,
      "step": 50
    },
    {
      "epoch": 0.0335946248600224,
      "grad_norm": 0.9971994757652283,
      "learning_rate": 2.4000000000000003e-06,
      "loss": 1.095,
      "step": 60
    },
    {
      "epoch": 0.03919372900335946,
      "grad_norm": 1.0557191371917725,
      "learning_rate": 2.8000000000000003e-06,
      "loss": 1.0847,
      "step": 70
    },
    {
      "epoch": 0.04479283314669653,
      "grad_norm": 1.0495893955230713,
      "learning_rate": 3.2000000000000003e-06,
      "loss": 1.0876,
      "step": 80
    },
    {
      "epoch": 0.05039193729003359,
      "grad_norm": 1.3365720510482788,
      "learning_rate": 3.6000000000000003e-06,
      "loss": 1.0793,
      "step": 90
    },
    {
      "epoch": 0.055991041433370664,
      "grad_norm": 1.6809189319610596,
      "learning_rate": 4.000000000000001e-06,
      "loss": 1.0773,
      "step": 100
    },
    {
      "epoch": 0.06159014557670773,
      "grad_norm": 1.5789872407913208,
      "learning_rate": 4.4e-06,
      "loss": 1.0603,
      "step": 110
    },
    {
      "epoch": 0.0671892497200448,
      "grad_norm": 1.7290959358215332,
      "learning_rate": 4.800000000000001e-06,
      "loss": 1.0405,
      "step": 120
    },
    {
      "epoch": 0.07278835386338185,
      "grad_norm": 1.8582388162612915,
      "learning_rate": 5.2e-06,
      "loss": 0.9975,
      "step": 130
    },
    {
      "epoch": 0.07838745800671892,
      "grad_norm": 3.331641674041748,
      "learning_rate": 5.600000000000001e-06,
      "loss": 0.9738,
      "step": 140
    },
    {
      "epoch": 0.083986562150056,
      "grad_norm": 2.2701704502105713,
      "learning_rate": 6e-06,
      "loss": 0.8941,
      "step": 150
    },
    {
      "epoch": 0.08958566629339305,
      "grad_norm": 2.757981538772583,
      "learning_rate": 6.4000000000000006e-06,
      "loss": 0.8684,
      "step": 160
    },
    {
      "epoch": 0.09518477043673013,
      "grad_norm": 4.024800777435303,
      "learning_rate": 6.800000000000001e-06,
      "loss": 0.8136,
      "step": 170
    },
    {
      "epoch": 0.10078387458006718,
      "grad_norm": 3.762896776199341,
      "learning_rate": 7.16e-06,
      "loss": 0.748,
      "step": 180
    },
    {
      "epoch": 0.10638297872340426,
      "grad_norm": 3.3089330196380615,
      "learning_rate": 7.5600000000000005e-06,
      "loss": 0.688,
      "step": 190
    },
    {
      "epoch": 0.11198208286674133,
      "grad_norm": 3.8051064014434814,
      "learning_rate": 7.960000000000002e-06,
      "loss": 0.6464,
      "step": 200
    },
    {
      "epoch": 0.11758118701007839,
      "grad_norm": 5.209081172943115,
      "learning_rate": 8.36e-06,
      "loss": 0.6009,
      "step": 210
    },
    {
      "epoch": 0.12318029115341546,
      "grad_norm": 8.377850532531738,
      "learning_rate": 8.720000000000001e-06,
      "loss": 0.5652,
      "step": 220
    },
    {
      "epoch": 0.12877939529675253,
      "grad_norm": 6.504951000213623,
      "learning_rate": 9.12e-06,
      "loss": 0.4676,
      "step": 230
    },
    {
      "epoch": 0.1343784994400896,
      "grad_norm": 6.289344310760498,
      "learning_rate": 9.52e-06,
      "loss": 0.5076,
      "step": 240
    },
    {
      "epoch": 0.13997760358342665,
      "grad_norm": 5.46185827255249,
      "learning_rate": 9.920000000000002e-06,
      "loss": 0.4545,
      "step": 250
    },
    {
      "epoch": 0.1455767077267637,
      "grad_norm": 8.21886157989502,
      "learning_rate": 1.0320000000000001e-05,
      "loss": 0.4782,
      "step": 260
    },
    {
      "epoch": 0.1511758118701008,
      "grad_norm": 4.826374530792236,
      "learning_rate": 1.072e-05,
      "loss": 0.4577,
      "step": 270
    },
    {
      "epoch": 0.15677491601343785,
      "grad_norm": 7.884671211242676,
      "learning_rate": 1.1120000000000002e-05,
      "loss": 0.4851,
      "step": 280
    },
    {
      "epoch": 0.1623740201567749,
      "grad_norm": 4.974587917327881,
      "learning_rate": 1.152e-05,
      "loss": 0.3985,
      "step": 290
    },
    {
      "epoch": 0.167973124300112,
      "grad_norm": 5.114544868469238,
      "learning_rate": 1.1920000000000001e-05,
      "loss": 0.4633,
      "step": 300
    },
    {
      "epoch": 0.17357222844344905,
      "grad_norm": 5.972825527191162,
      "learning_rate": 1.232e-05,
      "loss": 0.3662,
      "step": 310
    },
    {
      "epoch": 0.1791713325867861,
      "grad_norm": 12.370579719543457,
      "learning_rate": 1.2720000000000002e-05,
      "loss": 0.4287,
      "step": 320
    },
    {
      "epoch": 0.18477043673012317,
      "grad_norm": 3.9274661540985107,
      "learning_rate": 1.3120000000000001e-05,
      "loss": 0.361,
      "step": 330
    },
    {
      "epoch": 0.19036954087346025,
      "grad_norm": 8.238449096679688,
      "learning_rate": 1.3520000000000003e-05,
      "loss": 0.4176,
      "step": 340
    },
    {
      "epoch": 0.1959686450167973,
      "grad_norm": 4.016002178192139,
      "learning_rate": 1.392e-05,
      "loss": 0.3605,
      "step": 350
    },
    {
      "epoch": 0.20156774916013437,
      "grad_norm": 6.673572540283203,
      "learning_rate": 1.432e-05,
      "loss": 0.3556,
      "step": 360
    },
    {
      "epoch": 0.20716685330347145,
      "grad_norm": 8.395097732543945,
      "learning_rate": 1.4720000000000001e-05,
      "loss": 0.4068,
      "step": 370
    },
    {
      "epoch": 0.2127659574468085,
      "grad_norm": 3.8557538986206055,
      "learning_rate": 1.5120000000000001e-05,
      "loss": 0.3462,
      "step": 380
    },
    {
      "epoch": 0.21836506159014557,
      "grad_norm": 4.586132526397705,
      "learning_rate": 1.552e-05,
      "loss": 0.3989,
      "step": 390
    },
    {
      "epoch": 0.22396416573348266,
      "grad_norm": 7.933866500854492,
      "learning_rate": 1.5920000000000003e-05,
      "loss": 0.3433,
      "step": 400
    },
    {
      "epoch": 0.22956326987681971,
      "grad_norm": 8.76346206665039,
      "learning_rate": 1.632e-05,
      "loss": 0.3503,
      "step": 410
    },
    {
      "epoch": 0.23516237402015677,
      "grad_norm": 6.497847557067871,
      "learning_rate": 1.672e-05,
      "loss": 0.3822,
      "step": 420
    },
    {
      "epoch": 0.24076147816349383,
      "grad_norm": 7.036702632904053,
      "learning_rate": 1.7120000000000002e-05,
      "loss": 0.3552,
      "step": 430
    },
    {
      "epoch": 0.24636058230683092,
      "grad_norm": 8.90970230102539,
      "learning_rate": 1.752e-05,
      "loss": 0.3523,
      "step": 440
    },
    {
      "epoch": 0.251959686450168,
      "grad_norm": 6.259976863861084,
      "learning_rate": 1.792e-05,
      "loss": 0.4238,
      "step": 450
    },
    {
      "epoch": 0.25755879059350506,
      "grad_norm": 7.076536178588867,
      "learning_rate": 1.832e-05,
      "loss": 0.2958,
      "step": 460
    },
    {
      "epoch": 0.2631578947368421,
      "grad_norm": 6.899356365203857,
      "learning_rate": 1.8720000000000004e-05,
      "loss": 0.3592,
      "step": 470
    },
    {
      "epoch": 0.2687569988801792,
      "grad_norm": 14.016349792480469,
      "learning_rate": 1.912e-05,
      "loss": 0.3757,
      "step": 480
    },
    {
      "epoch": 0.27435610302351626,
      "grad_norm": 7.829667568206787,
      "learning_rate": 1.9520000000000003e-05,
      "loss": 0.3223,
      "step": 490
    },
    {
      "epoch": 0.2799552071668533,
      "grad_norm": 8.115921020507812,
      "learning_rate": 1.9920000000000002e-05,
      "loss": 0.347,
      "step": 500
    },
    {
      "epoch": 0.2855543113101904,
      "grad_norm": 3.423734188079834,
      "learning_rate": 1.9967064635652533e-05,
      "loss": 0.3071,
      "step": 510
    },
    {
      "epoch": 0.2911534154535274,
      "grad_norm": 4.108452320098877,
      "learning_rate": 1.99258954302182e-05,
      "loss": 0.3829,
      "step": 520
    },
    {
      "epoch": 0.2967525195968645,
      "grad_norm": 10.72187328338623,
      "learning_rate": 1.9884726224783863e-05,
      "loss": 0.3787,
      "step": 530
    },
    {
      "epoch": 0.3023516237402016,
      "grad_norm": 5.455792427062988,
      "learning_rate": 1.984355701934953e-05,
      "loss": 0.3774,
      "step": 540
    },
    {
      "epoch": 0.3079507278835386,
      "grad_norm": 4.412142753601074,
      "learning_rate": 1.9802387813915192e-05,
      "loss": 0.4039,
      "step": 550
    },
    {
      "epoch": 0.3135498320268757,
      "grad_norm": 4.344144821166992,
      "learning_rate": 1.976121860848086e-05,
      "loss": 0.2678,
      "step": 560
    },
    {
      "epoch": 0.3191489361702128,
      "grad_norm": 7.145920276641846,
      "learning_rate": 1.972004940304652e-05,
      "loss": 0.3531,
      "step": 570
    },
    {
      "epoch": 0.3247480403135498,
      "grad_norm": 4.337744235992432,
      "learning_rate": 1.9678880197612188e-05,
      "loss": 0.2417,
      "step": 580
    },
    {
      "epoch": 0.3303471444568869,
      "grad_norm": 12.2871675491333,
      "learning_rate": 1.963771099217785e-05,
      "loss": 0.2757,
      "step": 590
    },
    {
      "epoch": 0.335946248600224,
      "grad_norm": 10.416770935058594,
      "learning_rate": 1.9596541786743517e-05,
      "loss": 0.3402,
      "step": 600
    },
    {
      "epoch": 0.341545352743561,
      "grad_norm": 8.92452335357666,
      "learning_rate": 1.9555372581309183e-05,
      "loss": 0.3786,
      "step": 610
    },
    {
      "epoch": 0.3471444568868981,
      "grad_norm": 6.694119453430176,
      "learning_rate": 1.9514203375874846e-05,
      "loss": 0.3104,
      "step": 620
    },
    {
      "epoch": 0.3527435610302352,
      "grad_norm": 9.131437301635742,
      "learning_rate": 1.9473034170440513e-05,
      "loss": 0.3076,
      "step": 630
    },
    {
      "epoch": 0.3583426651735722,
      "grad_norm": 8.765005111694336,
      "learning_rate": 1.9431864965006176e-05,
      "loss": 0.3483,
      "step": 640
    },
    {
      "epoch": 0.3639417693169093,
      "grad_norm": 7.497739315032959,
      "learning_rate": 1.9390695759571842e-05,
      "loss": 0.2436,
      "step": 650
    },
    {
      "epoch": 0.36954087346024633,
      "grad_norm": 4.095083713531494,
      "learning_rate": 1.934952655413751e-05,
      "loss": 0.3511,
      "step": 660
    },
    {
      "epoch": 0.3751399776035834,
      "grad_norm": 5.35698127746582,
      "learning_rate": 1.930835734870317e-05,
      "loss": 0.3971,
      "step": 670
    },
    {
      "epoch": 0.3807390817469205,
      "grad_norm": 5.940741539001465,
      "learning_rate": 1.9267188143268835e-05,
      "loss": 0.3257,
      "step": 680
    },
    {
      "epoch": 0.38633818589025753,
      "grad_norm": 5.413826942443848,
      "learning_rate": 1.92260189378345e-05,
      "loss": 0.3165,
      "step": 690
    },
    {
      "epoch": 0.3919372900335946,
      "grad_norm": 10.46671199798584,
      "learning_rate": 1.9184849732400167e-05,
      "loss": 0.3011,
      "step": 700
    },
    {
      "epoch": 0.3975363941769317,
      "grad_norm": 8.04304027557373,
      "learning_rate": 1.914368052696583e-05,
      "loss": 0.2959,
      "step": 710
    },
    {
      "epoch": 0.40313549832026874,
      "grad_norm": 8.961655616760254,
      "learning_rate": 1.9102511321531497e-05,
      "loss": 0.3159,
      "step": 720
    },
    {
      "epoch": 0.4087346024636058,
      "grad_norm": 7.5401411056518555,
      "learning_rate": 1.906134211609716e-05,
      "loss": 0.2867,
      "step": 730
    },
    {
      "epoch": 0.4143337066069429,
      "grad_norm": 6.297504425048828,
      "learning_rate": 1.9020172910662826e-05,
      "loss": 0.2947,
      "step": 740
    },
    {
      "epoch": 0.41993281075027994,
      "grad_norm": 3.8668878078460693,
      "learning_rate": 1.8979003705228492e-05,
      "loss": 0.2645,
      "step": 750
    },
    {
      "epoch": 0.425531914893617,
      "grad_norm": 3.7618632316589355,
      "learning_rate": 1.8937834499794155e-05,
      "loss": 0.2879,
      "step": 760
    },
    {
      "epoch": 0.4311310190369541,
      "grad_norm": 5.220946788787842,
      "learning_rate": 1.8896665294359818e-05,
      "loss": 0.3826,
      "step": 770
    },
    {
      "epoch": 0.43673012318029114,
      "grad_norm": 3.725432872772217,
      "learning_rate": 1.8855496088925485e-05,
      "loss": 0.2347,
      "step": 780
    },
    {
      "epoch": 0.4423292273236282,
      "grad_norm": 6.0286383628845215,
      "learning_rate": 1.881432688349115e-05,
      "loss": 0.3231,
      "step": 790
    },
    {
      "epoch": 0.4479283314669653,
      "grad_norm": 5.878318786621094,
      "learning_rate": 1.8773157678056814e-05,
      "loss": 0.2867,
      "step": 800
    },
    {
      "epoch": 0.45352743561030234,
      "grad_norm": 6.067507743835449,
      "learning_rate": 1.873198847262248e-05,
      "loss": 0.2693,
      "step": 810
    },
    {
      "epoch": 0.45912653975363943,
      "grad_norm": 5.397449016571045,
      "learning_rate": 1.8690819267188143e-05,
      "loss": 0.2424,
      "step": 820
    },
    {
      "epoch": 0.46472564389697646,
      "grad_norm": 6.401192665100098,
      "learning_rate": 1.864965006175381e-05,
      "loss": 0.2402,
      "step": 830
    },
    {
      "epoch": 0.47032474804031354,
      "grad_norm": 7.466775894165039,
      "learning_rate": 1.8608480856319476e-05,
      "loss": 0.3493,
      "step": 840
    },
    {
      "epoch": 0.47592385218365063,
      "grad_norm": 4.415462493896484,
      "learning_rate": 1.856731165088514e-05,
      "loss": 0.269,
      "step": 850
    },
    {
      "epoch": 0.48152295632698766,
      "grad_norm": 2.753971815109253,
      "learning_rate": 1.8526142445450805e-05,
      "loss": 0.2622,
      "step": 860
    },
    {
      "epoch": 0.48712206047032475,
      "grad_norm": 5.257455348968506,
      "learning_rate": 1.848497324001647e-05,
      "loss": 0.2825,
      "step": 870
    },
    {
      "epoch": 0.49272116461366183,
      "grad_norm": 9.084284782409668,
      "learning_rate": 1.8443804034582135e-05,
      "loss": 0.3222,
      "step": 880
    },
    {
      "epoch": 0.49832026875699886,
      "grad_norm": 5.179415702819824,
      "learning_rate": 1.8402634829147798e-05,
      "loss": 0.2416,
      "step": 890
    },
    {
      "epoch": 0.503919372900336,
      "grad_norm": 8.317529678344727,
      "learning_rate": 1.8361465623713464e-05,
      "loss": 0.307,
      "step": 900
    },
    {
      "epoch": 0.509518477043673,
      "grad_norm": 3.713149309158325,
      "learning_rate": 1.8320296418279127e-05,
      "loss": 0.2543,
      "step": 910
    },
    {
      "epoch": 0.5151175811870101,
      "grad_norm": 5.214797496795654,
      "learning_rate": 1.8279127212844793e-05,
      "loss": 0.2491,
      "step": 920
    },
    {
      "epoch": 0.5207166853303471,
      "grad_norm": 5.9826340675354,
      "learning_rate": 1.823795800741046e-05,
      "loss": 0.2978,
      "step": 930
    },
    {
      "epoch": 0.5263157894736842,
      "grad_norm": 6.834679126739502,
      "learning_rate": 1.8196788801976123e-05,
      "loss": 0.3099,
      "step": 940
    },
    {
      "epoch": 0.5319148936170213,
      "grad_norm": 6.304373264312744,
      "learning_rate": 1.815561959654179e-05,
      "loss": 0.2377,
      "step": 950
    },
    {
      "epoch": 0.5375139977603584,
      "grad_norm": 11.332296371459961,
      "learning_rate": 1.8114450391107452e-05,
      "loss": 0.2477,
      "step": 960
    },
    {
      "epoch": 0.5431131019036954,
      "grad_norm": 7.899176597595215,
      "learning_rate": 1.807328118567312e-05,
      "loss": 0.251,
      "step": 970
    },
    {
      "epoch": 0.5487122060470325,
      "grad_norm": 9.604595184326172,
      "learning_rate": 1.803211198023878e-05,
      "loss": 0.2399,
      "step": 980
    },
    {
      "epoch": 0.5543113101903695,
      "grad_norm": 5.4935832023620605,
      "learning_rate": 1.7990942774804448e-05,
      "loss": 0.2232,
      "step": 990
    },
    {
      "epoch": 0.5599104143337066,
      "grad_norm": 9.414862632751465,
      "learning_rate": 1.794977356937011e-05,
      "loss": 0.3444,
      "step": 1000
    },
    {
      "epoch": 0.5655095184770437,
      "grad_norm": 5.983129501342773,
      "learning_rate": 1.7908604363935777e-05,
      "loss": 0.3279,
      "step": 1010
    },
    {
      "epoch": 0.5711086226203808,
      "grad_norm": 3.621265411376953,
      "learning_rate": 1.7867435158501444e-05,
      "loss": 0.2808,
      "step": 1020
    },
    {
      "epoch": 0.5767077267637178,
      "grad_norm": 2.061856508255005,
      "learning_rate": 1.7826265953067107e-05,
      "loss": 0.3026,
      "step": 1030
    },
    {
      "epoch": 0.5823068309070548,
      "grad_norm": 7.366219997406006,
      "learning_rate": 1.7785096747632773e-05,
      "loss": 0.2312,
      "step": 1040
    },
    {
      "epoch": 0.5879059350503919,
      "grad_norm": 6.690503120422363,
      "learning_rate": 1.774392754219844e-05,
      "loss": 0.2369,
      "step": 1050
    },
    {
      "epoch": 0.593505039193729,
      "grad_norm": 7.339536666870117,
      "learning_rate": 1.7702758336764102e-05,
      "loss": 0.2663,
      "step": 1060
    },
    {
      "epoch": 0.5991041433370661,
      "grad_norm": 10.654436111450195,
      "learning_rate": 1.7661589131329765e-05,
      "loss": 0.2407,
      "step": 1070
    },
    {
      "epoch": 0.6047032474804032,
      "grad_norm": 8.342461585998535,
      "learning_rate": 1.762041992589543e-05,
      "loss": 0.2257,
      "step": 1080
    },
    {
      "epoch": 0.6103023516237402,
      "grad_norm": 4.9448771476745605,
      "learning_rate": 1.7579250720461095e-05,
      "loss": 0.252,
      "step": 1090
    },
    {
      "epoch": 0.6159014557670772,
      "grad_norm": 3.0635147094726562,
      "learning_rate": 1.753808151502676e-05,
      "loss": 0.2311,
      "step": 1100
    },
    {
      "epoch": 0.6215005599104143,
      "grad_norm": 4.4998779296875,
      "learning_rate": 1.7496912309592427e-05,
      "loss": 0.2751,
      "step": 1110
    },
    {
      "epoch": 0.6270996640537514,
      "grad_norm": 4.129617214202881,
      "learning_rate": 1.745574310415809e-05,
      "loss": 0.2402,
      "step": 1120
    },
    {
      "epoch": 0.6326987681970885,
      "grad_norm": 11.641082763671875,
      "learning_rate": 1.7414573898723757e-05,
      "loss": 0.2675,
      "step": 1130
    },
    {
      "epoch": 0.6382978723404256,
      "grad_norm": 11.065546035766602,
      "learning_rate": 1.7373404693289423e-05,
      "loss": 0.2509,
      "step": 1140
    },
    {
      "epoch": 0.6438969764837627,
      "grad_norm": 8.128022193908691,
      "learning_rate": 1.7332235487855086e-05,
      "loss": 0.2333,
      "step": 1150
    },
    {
      "epoch": 0.6494960806270996,
      "grad_norm": 8.115355491638184,
      "learning_rate": 1.729106628242075e-05,
      "loss": 0.2736,
      "step": 1160
    },
    {
      "epoch": 0.6550951847704367,
      "grad_norm": 10.47752857208252,
      "learning_rate": 1.7249897076986415e-05,
      "loss": 0.2321,
      "step": 1170
    },
    {
      "epoch": 0.6606942889137738,
      "grad_norm": 4.372245788574219,
      "learning_rate": 1.720872787155208e-05,
      "loss": 0.2792,
      "step": 1180
    },
    {
      "epoch": 0.6662933930571109,
      "grad_norm": 4.9245429039001465,
      "learning_rate": 1.7167558666117745e-05,
      "loss": 0.3315,
      "step": 1190
    },
    {
      "epoch": 0.671892497200448,
      "grad_norm": 7.7493767738342285,
      "learning_rate": 1.712638946068341e-05,
      "loss": 0.3196,
      "step": 1200
    },
    {
      "epoch": 0.6774916013437849,
      "grad_norm": 5.098292350769043,
      "learning_rate": 1.7085220255249074e-05,
      "loss": 0.2585,
      "step": 1210
    },
    {
      "epoch": 0.683090705487122,
      "grad_norm": 6.261331081390381,
      "learning_rate": 1.704405104981474e-05,
      "loss": 0.2721,
      "step": 1220
    },
    {
      "epoch": 0.6886898096304591,
      "grad_norm": 7.186995983123779,
      "learning_rate": 1.7002881844380407e-05,
      "loss": 0.3485,
      "step": 1230
    },
    {
      "epoch": 0.6942889137737962,
      "grad_norm": 9.727849960327148,
      "learning_rate": 1.696171263894607e-05,
      "loss": 0.2878,
      "step": 1240
    },
    {
      "epoch": 0.6998880179171333,
      "grad_norm": 6.8565354347229,
      "learning_rate": 1.6920543433511733e-05,
      "loss": 0.2517,
      "step": 1250
    },
    {
      "epoch": 0.7054871220604704,
      "grad_norm": 4.050683498382568,
      "learning_rate": 1.68793742280774e-05,
      "loss": 0.2336,
      "step": 1260
    },
    {
      "epoch": 0.7110862262038073,
      "grad_norm": 5.055780410766602,
      "learning_rate": 1.6838205022643062e-05,
      "loss": 0.3636,
      "step": 1270
    },
    {
      "epoch": 0.7166853303471444,
      "grad_norm": 7.8397345542907715,
      "learning_rate": 1.679703581720873e-05,
      "loss": 0.2648,
      "step": 1280
    },
    {
      "epoch": 0.7222844344904815,
      "grad_norm": 10.702211380004883,
      "learning_rate": 1.6755866611774395e-05,
      "loss": 0.2193,
      "step": 1290
    },
    {
      "epoch": 0.7278835386338186,
      "grad_norm": 7.795886993408203,
      "learning_rate": 1.6714697406340058e-05,
      "loss": 0.3155,
      "step": 1300
    },
    {
      "epoch": 0.7334826427771557,
      "grad_norm": 4.9754157066345215,
      "learning_rate": 1.6673528200905724e-05,
      "loss": 0.2533,
      "step": 1310
    },
    {
      "epoch": 0.7390817469204927,
      "grad_norm": 4.494987964630127,
      "learning_rate": 1.663235899547139e-05,
      "loss": 0.2207,
      "step": 1320
    },
    {
      "epoch": 0.7446808510638298,
      "grad_norm": 4.821629047393799,
      "learning_rate": 1.6591189790037054e-05,
      "loss": 0.2378,
      "step": 1330
    },
    {
      "epoch": 0.7502799552071668,
      "grad_norm": 8.858943939208984,
      "learning_rate": 1.655002058460272e-05,
      "loss": 0.2812,
      "step": 1340
    },
    {
      "epoch": 0.7558790593505039,
      "grad_norm": 4.343780517578125,
      "learning_rate": 1.6508851379168383e-05,
      "loss": 0.2327,
      "step": 1350
    },
    {
      "epoch": 0.761478163493841,
      "grad_norm": 3.031315803527832,
      "learning_rate": 1.6467682173734046e-05,
      "loss": 0.2598,
      "step": 1360
    },
    {
      "epoch": 0.7670772676371781,
      "grad_norm": 3.0782995223999023,
      "learning_rate": 1.6426512968299712e-05,
      "loss": 0.2482,
      "step": 1370
    },
    {
      "epoch": 0.7726763717805151,
      "grad_norm": 6.165716648101807,
      "learning_rate": 1.638534376286538e-05,
      "loss": 0.2887,
      "step": 1380
    },
    {
      "epoch": 0.7782754759238522,
      "grad_norm": 3.7976150512695312,
      "learning_rate": 1.634417455743104e-05,
      "loss": 0.2653,
      "step": 1390
    },
    {
      "epoch": 0.7838745800671892,
      "grad_norm": 4.670191287994385,
      "learning_rate": 1.6303005351996708e-05,
      "loss": 0.2797,
      "step": 1400
    },
    {
      "epoch": 0.7894736842105263,
      "grad_norm": 7.756983280181885,
      "learning_rate": 1.6261836146562374e-05,
      "loss": 0.3012,
      "step": 1410
    },
    {
      "epoch": 0.7950727883538634,
      "grad_norm": 9.753016471862793,
      "learning_rate": 1.6220666941128037e-05,
      "loss": 0.2728,
      "step": 1420
    },
    {
      "epoch": 0.8006718924972005,
      "grad_norm": 5.580300807952881,
      "learning_rate": 1.6179497735693704e-05,
      "loss": 0.2843,
      "step": 1430
    },
    {
      "epoch": 0.8062709966405375,
      "grad_norm": 10.026930809020996,
      "learning_rate": 1.613832853025937e-05,
      "loss": 0.2421,
      "step": 1440
    },
    {
      "epoch": 0.8118701007838746,
      "grad_norm": 6.20858907699585,
      "learning_rate": 1.609715932482503e-05,
      "loss": 0.2277,
      "step": 1450
    },
    {
      "epoch": 0.8174692049272116,
      "grad_norm": 5.221068859100342,
      "learning_rate": 1.6055990119390696e-05,
      "loss": 0.2656,
      "step": 1460
    },
    {
      "epoch": 0.8230683090705487,
      "grad_norm": 6.141912937164307,
      "learning_rate": 1.6014820913956362e-05,
      "loss": 0.2472,
      "step": 1470
    },
    {
      "epoch": 0.8286674132138858,
      "grad_norm": 3.984757423400879,
      "learning_rate": 1.5973651708522025e-05,
      "loss": 0.2003,
      "step": 1480
    },
    {
      "epoch": 0.8342665173572228,
      "grad_norm": 3.6791281700134277,
      "learning_rate": 1.5932482503087692e-05,
      "loss": 0.2749,
      "step": 1490
    },
    {
      "epoch": 0.8398656215005599,
      "grad_norm": 5.154890537261963,
      "learning_rate": 1.5891313297653358e-05,
      "loss": 0.2876,
      "step": 1500
    },
    {
      "epoch": 0.845464725643897,
      "grad_norm": 3.867419481277466,
      "learning_rate": 1.585014409221902e-05,
      "loss": 0.2459,
      "step": 1510
    },
    {
      "epoch": 0.851063829787234,
      "grad_norm": 8.3186616897583,
      "learning_rate": 1.5808974886784687e-05,
      "loss": 0.2642,
      "step": 1520
    },
    {
      "epoch": 0.8566629339305711,
      "grad_norm": 3.1232852935791016,
      "learning_rate": 1.5767805681350354e-05,
      "loss": 0.2449,
      "step": 1530
    },
    {
      "epoch": 0.8622620380739082,
      "grad_norm": 5.37439489364624,
      "learning_rate": 1.5726636475916013e-05,
      "loss": 0.2992,
      "step": 1540
    },
    {
      "epoch": 0.8678611422172452,
      "grad_norm": 4.090015888214111,
      "learning_rate": 1.568546727048168e-05,
      "loss": 0.2192,
      "step": 1550
    },
    {
      "epoch": 0.8734602463605823,
      "grad_norm": 4.271711349487305,
      "learning_rate": 1.5644298065047346e-05,
      "loss": 0.2257,
      "step": 1560
    },
    {
      "epoch": 0.8790593505039194,
      "grad_norm": 5.264697074890137,
      "learning_rate": 1.560312885961301e-05,
      "loss": 0.2333,
      "step": 1570
    },
    {
      "epoch": 0.8846584546472565,
      "grad_norm": 9.523970603942871,
      "learning_rate": 1.5561959654178675e-05,
      "loss": 0.2485,
      "step": 1580
    },
    {
      "epoch": 0.8902575587905935,
      "grad_norm": 5.1288251876831055,
      "learning_rate": 1.5520790448744342e-05,
      "loss": 0.2609,
      "step": 1590
    },
    {
      "epoch": 0.8958566629339306,
      "grad_norm": 6.496960639953613,
      "learning_rate": 1.5479621243310005e-05,
      "loss": 0.1761,
      "step": 1600
    },
    {
      "epoch": 0.9014557670772676,
      "grad_norm": 3.116694450378418,
      "learning_rate": 1.543845203787567e-05,
      "loss": 0.2668,
      "step": 1610
    },
    {
      "epoch": 0.9070548712206047,
      "grad_norm": 4.07711124420166,
      "learning_rate": 1.5397282832441338e-05,
      "loss": 0.2955,
      "step": 1620
    },
    {
      "epoch": 0.9126539753639418,
      "grad_norm": 5.5077080726623535,
      "learning_rate": 1.5356113627007e-05,
      "loss": 0.2467,
      "step": 1630
    },
    {
      "epoch": 0.9182530795072789,
      "grad_norm": 7.221078872680664,
      "learning_rate": 1.5314944421572664e-05,
      "loss": 0.289,
      "step": 1640
    },
    {
      "epoch": 0.9238521836506159,
      "grad_norm": 5.116714954376221,
      "learning_rate": 1.527377521613833e-05,
      "loss": 0.2304,
      "step": 1650
    },
    {
      "epoch": 0.9294512877939529,
      "grad_norm": 7.030979156494141,
      "learning_rate": 1.5232606010703995e-05,
      "loss": 0.2681,
      "step": 1660
    },
    {
      "epoch": 0.93505039193729,
      "grad_norm": 3.7065839767456055,
      "learning_rate": 1.519143680526966e-05,
      "loss": 0.216,
      "step": 1670
    },
    {
      "epoch": 0.9406494960806271,
      "grad_norm": 2.4307498931884766,
      "learning_rate": 1.5150267599835324e-05,
      "loss": 0.209,
      "step": 1680
    },
    {
      "epoch": 0.9462486002239642,
      "grad_norm": 5.356419563293457,
      "learning_rate": 1.510909839440099e-05,
      "loss": 0.266,
      "step": 1690
    },
    {
      "epoch": 0.9518477043673013,
      "grad_norm": 2.5440940856933594,
      "learning_rate": 1.5067929188966655e-05,
      "loss": 0.2293,
      "step": 1700
    },
    {
      "epoch": 0.9574468085106383,
      "grad_norm": 6.932008743286133,
      "learning_rate": 1.502675998353232e-05,
      "loss": 0.2101,
      "step": 1710
    },
    {
      "epoch": 0.9630459126539753,
      "grad_norm": 7.431680202484131,
      "learning_rate": 1.4985590778097984e-05,
      "loss": 0.2312,
      "step": 1720
    },
    {
      "epoch": 0.9686450167973124,
      "grad_norm": 4.903409481048584,
      "learning_rate": 1.494442157266365e-05,
      "loss": 0.2958,
      "step": 1730
    },
    {
      "epoch": 0.9742441209406495,
      "grad_norm": 5.518984794616699,
      "learning_rate": 1.4903252367229314e-05,
      "loss": 0.2673,
      "step": 1740
    },
    {
      "epoch": 0.9798432250839866,
      "grad_norm": 4.0694499015808105,
      "learning_rate": 1.4862083161794978e-05,
      "loss": 0.2727,
      "step": 1750
    },
    {
      "epoch": 0.9854423292273237,
      "grad_norm": 3.983914613723755,
      "learning_rate": 1.4820913956360643e-05,
      "loss": 0.3074,
      "step": 1760
    },
    {
      "epoch": 0.9910414333706606,
      "grad_norm": 3.6404969692230225,
      "learning_rate": 1.4779744750926308e-05,
      "loss": 0.2171,
      "step": 1770
    },
    {
      "epoch": 0.9966405375139977,
      "grad_norm": 3.9914932250976562,
      "learning_rate": 1.4738575545491974e-05,
      "loss": 0.1978,
      "step": 1780
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9074748040313549,
      "eval_f1": 0.9079590141661019,
      "eval_loss": 0.2502007484436035,
      "eval_precision": 0.9104935886736517,
      "eval_recall": 0.9074748040313549,
      "eval_runtime": 504.1139,
      "eval_samples_per_second": 28.343,
      "eval_steps_per_second": 0.444,
      "step": 1786
    },
    {
      "epoch": 1.002239641657335,
      "grad_norm": 4.953564643859863,
      "learning_rate": 1.4697406340057639e-05,
      "loss": 0.2221,
      "step": 1790
    },
    {
      "epoch": 1.007838745800672,
      "grad_norm": 8.79792308807373,
      "learning_rate": 1.4656237134623303e-05,
      "loss": 0.2118,
      "step": 1800
    },
    {
      "epoch": 1.0134378499440089,
      "grad_norm": 13.206968307495117,
      "learning_rate": 1.4615067929188968e-05,
      "loss": 0.2567,
      "step": 1810
    },
    {
      "epoch": 1.019036954087346,
      "grad_norm": 4.353593826293945,
      "learning_rate": 1.4573898723754634e-05,
      "loss": 0.1707,
      "step": 1820
    },
    {
      "epoch": 1.024636058230683,
      "grad_norm": 4.558290958404541,
      "learning_rate": 1.4532729518320297e-05,
      "loss": 0.2051,
      "step": 1830
    },
    {
      "epoch": 1.0302351623740202,
      "grad_norm": 7.654868125915527,
      "learning_rate": 1.4491560312885962e-05,
      "loss": 0.196,
      "step": 1840
    },
    {
      "epoch": 1.0358342665173572,
      "grad_norm": 6.904658317565918,
      "learning_rate": 1.4450391107451627e-05,
      "loss": 0.2749,
      "step": 1850
    },
    {
      "epoch": 1.0414333706606942,
      "grad_norm": 3.640562057495117,
      "learning_rate": 1.4409221902017291e-05,
      "loss": 0.2192,
      "step": 1860
    },
    {
      "epoch": 1.0470324748040314,
      "grad_norm": 2.386702537536621,
      "learning_rate": 1.4368052696582958e-05,
      "loss": 0.2355,
      "step": 1870
    },
    {
      "epoch": 1.0526315789473684,
      "grad_norm": 4.129228115081787,
      "learning_rate": 1.4326883491148622e-05,
      "loss": 0.2408,
      "step": 1880
    },
    {
      "epoch": 1.0582306830907056,
      "grad_norm": 5.58174991607666,
      "learning_rate": 1.4285714285714287e-05,
      "loss": 0.2039,
      "step": 1890
    },
    {
      "epoch": 1.0638297872340425,
      "grad_norm": 4.588379859924316,
      "learning_rate": 1.4244545080279952e-05,
      "loss": 0.1972,
      "step": 1900
    },
    {
      "epoch": 1.0694288913773797,
      "grad_norm": 1.920548915863037,
      "learning_rate": 1.4203375874845618e-05,
      "loss": 0.234,
      "step": 1910
    },
    {
      "epoch": 1.0750279955207167,
      "grad_norm": 8.295291900634766,
      "learning_rate": 1.4162206669411283e-05,
      "loss": 0.1539,
      "step": 1920
    },
    {
      "epoch": 1.0806270996640537,
      "grad_norm": 2.9672586917877197,
      "learning_rate": 1.4121037463976946e-05,
      "loss": 0.1672,
      "step": 1930
    },
    {
      "epoch": 1.0862262038073909,
      "grad_norm": 2.670293092727661,
      "learning_rate": 1.407986825854261e-05,
      "loss": 0.2238,
      "step": 1940
    },
    {
      "epoch": 1.0918253079507279,
      "grad_norm": 7.867208957672119,
      "learning_rate": 1.4038699053108275e-05,
      "loss": 0.2092,
      "step": 1950
    },
    {
      "epoch": 1.097424412094065,
      "grad_norm": 6.694972991943359,
      "learning_rate": 1.3997529847673942e-05,
      "loss": 0.2574,
      "step": 1960
    },
    {
      "epoch": 1.103023516237402,
      "grad_norm": 3.7446818351745605,
      "learning_rate": 1.3956360642239606e-05,
      "loss": 0.2343,
      "step": 1970
    },
    {
      "epoch": 1.108622620380739,
      "grad_norm": 2.6634597778320312,
      "learning_rate": 1.3915191436805271e-05,
      "loss": 0.2274,
      "step": 1980
    },
    {
      "epoch": 1.1142217245240762,
      "grad_norm": 7.640474319458008,
      "learning_rate": 1.3874022231370936e-05,
      "loss": 0.2283,
      "step": 1990
    },
    {
      "epoch": 1.1198208286674132,
      "grad_norm": 3.8394510746002197,
      "learning_rate": 1.3832853025936602e-05,
      "loss": 0.1861,
      "step": 2000
    },
    {
      "epoch": 1.1254199328107504,
      "grad_norm": 7.788141250610352,
      "learning_rate": 1.3791683820502267e-05,
      "loss": 0.2707,
      "step": 2010
    },
    {
      "epoch": 1.1310190369540873,
      "grad_norm": 3.386812210083008,
      "learning_rate": 1.3750514615067931e-05,
      "loss": 0.2091,
      "step": 2020
    },
    {
      "epoch": 1.1366181410974243,
      "grad_norm": 6.00430965423584,
      "learning_rate": 1.3709345409633594e-05,
      "loss": 0.2635,
      "step": 2030
    },
    {
      "epoch": 1.1422172452407615,
      "grad_norm": 7.725488185882568,
      "learning_rate": 1.3668176204199259e-05,
      "loss": 0.2001,
      "step": 2040
    },
    {
      "epoch": 1.1478163493840985,
      "grad_norm": 5.471164703369141,
      "learning_rate": 1.3627006998764925e-05,
      "loss": 0.2429,
      "step": 2050
    },
    {
      "epoch": 1.1534154535274357,
      "grad_norm": 5.211417198181152,
      "learning_rate": 1.358583779333059e-05,
      "loss": 0.1997,
      "step": 2060
    },
    {
      "epoch": 1.1590145576707727,
      "grad_norm": 3.5635132789611816,
      "learning_rate": 1.3544668587896255e-05,
      "loss": 0.2175,
      "step": 2070
    },
    {
      "epoch": 1.1646136618141099,
      "grad_norm": 3.373448371887207,
      "learning_rate": 1.350349938246192e-05,
      "loss": 0.1914,
      "step": 2080
    },
    {
      "epoch": 1.1702127659574468,
      "grad_norm": 2.959928512573242,
      "learning_rate": 1.3462330177027586e-05,
      "loss": 0.2365,
      "step": 2090
    },
    {
      "epoch": 1.1758118701007838,
      "grad_norm": 6.021612644195557,
      "learning_rate": 1.342116097159325e-05,
      "loss": 0.2153,
      "step": 2100
    },
    {
      "epoch": 1.181410974244121,
      "grad_norm": 5.4621171951293945,
      "learning_rate": 1.3379991766158915e-05,
      "loss": 0.226,
      "step": 2110
    },
    {
      "epoch": 1.187010078387458,
      "grad_norm": 2.799689292907715,
      "learning_rate": 1.3338822560724578e-05,
      "loss": 0.1647,
      "step": 2120
    },
    {
      "epoch": 1.192609182530795,
      "grad_norm": 2.1814210414886475,
      "learning_rate": 1.3297653355290243e-05,
      "loss": 0.2062,
      "step": 2130
    },
    {
      "epoch": 1.1982082866741322,
      "grad_norm": 12.682969093322754,
      "learning_rate": 1.3256484149855909e-05,
      "loss": 0.2618,
      "step": 2140
    },
    {
      "epoch": 1.2038073908174691,
      "grad_norm": 4.658006191253662,
      "learning_rate": 1.3215314944421574e-05,
      "loss": 0.2705,
      "step": 2150
    },
    {
      "epoch": 1.2094064949608063,
      "grad_norm": 5.8360161781311035,
      "learning_rate": 1.3174145738987238e-05,
      "loss": 0.234,
      "step": 2160
    },
    {
      "epoch": 1.2150055991041433,
      "grad_norm": 6.579841136932373,
      "learning_rate": 1.3132976533552903e-05,
      "loss": 0.1838,
      "step": 2170
    },
    {
      "epoch": 1.2206047032474805,
      "grad_norm": 5.396886825561523,
      "learning_rate": 1.309180732811857e-05,
      "loss": 0.2902,
      "step": 2180
    },
    {
      "epoch": 1.2262038073908175,
      "grad_norm": 5.452439308166504,
      "learning_rate": 1.3050638122684234e-05,
      "loss": 0.243,
      "step": 2190
    },
    {
      "epoch": 1.2318029115341544,
      "grad_norm": 5.980996131896973,
      "learning_rate": 1.3009468917249899e-05,
      "loss": 0.1956,
      "step": 2200
    },
    {
      "epoch": 1.2374020156774916,
      "grad_norm": 7.692512512207031,
      "learning_rate": 1.2968299711815563e-05,
      "loss": 0.1261,
      "step": 2210
    },
    {
      "epoch": 1.2430011198208286,
      "grad_norm": 4.934264659881592,
      "learning_rate": 1.2927130506381226e-05,
      "loss": 0.1933,
      "step": 2220
    },
    {
      "epoch": 1.2486002239641658,
      "grad_norm": 7.145289897918701,
      "learning_rate": 1.2885961300946893e-05,
      "loss": 0.2833,
      "step": 2230
    },
    {
      "epoch": 1.2541993281075028,
      "grad_norm": 4.259737014770508,
      "learning_rate": 1.2844792095512557e-05,
      "loss": 0.2371,
      "step": 2240
    },
    {
      "epoch": 1.25979843225084,
      "grad_norm": 2.892298936843872,
      "learning_rate": 1.2803622890078222e-05,
      "loss": 0.2122,
      "step": 2250
    },
    {
      "epoch": 1.265397536394177,
      "grad_norm": 3.68591570854187,
      "learning_rate": 1.2762453684643887e-05,
      "loss": 0.2188,
      "step": 2260
    },
    {
      "epoch": 1.270996640537514,
      "grad_norm": 5.5284104347229,
      "learning_rate": 1.2721284479209553e-05,
      "loss": 0.2797,
      "step": 2270
    },
    {
      "epoch": 1.2765957446808511,
      "grad_norm": 4.469930171966553,
      "learning_rate": 1.2680115273775218e-05,
      "loss": 0.1975,
      "step": 2280
    },
    {
      "epoch": 1.282194848824188,
      "grad_norm": 3.7279067039489746,
      "learning_rate": 1.2638946068340883e-05,
      "loss": 0.22,
      "step": 2290
    },
    {
      "epoch": 1.287793952967525,
      "grad_norm": 2.9019100666046143,
      "learning_rate": 1.2597776862906547e-05,
      "loss": 0.1474,
      "step": 2300
    },
    {
      "epoch": 1.2933930571108623,
      "grad_norm": 4.3261189460754395,
      "learning_rate": 1.2556607657472214e-05,
      "loss": 0.1895,
      "step": 2310
    },
    {
      "epoch": 1.2989921612541993,
      "grad_norm": 5.8429646492004395,
      "learning_rate": 1.2515438452037877e-05,
      "loss": 0.1742,
      "step": 2320
    },
    {
      "epoch": 1.3045912653975364,
      "grad_norm": 7.202151775360107,
      "learning_rate": 1.2474269246603541e-05,
      "loss": 0.2762,
      "step": 2330
    },
    {
      "epoch": 1.3101903695408734,
      "grad_norm": 4.971565246582031,
      "learning_rate": 1.2433100041169206e-05,
      "loss": 0.1432,
      "step": 2340
    },
    {
      "epoch": 1.3157894736842106,
      "grad_norm": 10.309562683105469,
      "learning_rate": 1.239193083573487e-05,
      "loss": 0.2588,
      "step": 2350
    },
    {
      "epoch": 1.3213885778275476,
      "grad_norm": 8.362977027893066,
      "learning_rate": 1.2350761630300537e-05,
      "loss": 0.2215,
      "step": 2360
    },
    {
      "epoch": 1.3269876819708846,
      "grad_norm": 2.4748077392578125,
      "learning_rate": 1.2309592424866202e-05,
      "loss": 0.1928,
      "step": 2370
    },
    {
      "epoch": 1.3325867861142218,
      "grad_norm": 3.3665668964385986,
      "learning_rate": 1.2268423219431866e-05,
      "loss": 0.2046,
      "step": 2380
    },
    {
      "epoch": 1.3381858902575587,
      "grad_norm": 2.650690793991089,
      "learning_rate": 1.2227254013997531e-05,
      "loss": 0.2237,
      "step": 2390
    },
    {
      "epoch": 1.343784994400896,
      "grad_norm": 4.184168338775635,
      "learning_rate": 1.2186084808563197e-05,
      "loss": 0.1717,
      "step": 2400
    },
    {
      "epoch": 1.349384098544233,
      "grad_norm": 4.652702808380127,
      "learning_rate": 1.214491560312886e-05,
      "loss": 0.2642,
      "step": 2410
    },
    {
      "epoch": 1.35498320268757,
      "grad_norm": 3.6119115352630615,
      "learning_rate": 1.2103746397694525e-05,
      "loss": 0.2091,
      "step": 2420
    },
    {
      "epoch": 1.360582306830907,
      "grad_norm": 4.683189868927002,
      "learning_rate": 1.206257719226019e-05,
      "loss": 0.1982,
      "step": 2430
    },
    {
      "epoch": 1.366181410974244,
      "grad_norm": 2.767296552658081,
      "learning_rate": 1.2021407986825854e-05,
      "loss": 0.1544,
      "step": 2440
    },
    {
      "epoch": 1.3717805151175813,
      "grad_norm": 13.499808311462402,
      "learning_rate": 1.198023878139152e-05,
      "loss": 0.1871,
      "step": 2450
    },
    {
      "epoch": 1.3773796192609182,
      "grad_norm": 6.9749040603637695,
      "learning_rate": 1.1939069575957185e-05,
      "loss": 0.1992,
      "step": 2460
    },
    {
      "epoch": 1.3829787234042552,
      "grad_norm": 5.556722164154053,
      "learning_rate": 1.189790037052285e-05,
      "loss": 0.217,
      "step": 2470
    },
    {
      "epoch": 1.3885778275475924,
      "grad_norm": 3.0006048679351807,
      "learning_rate": 1.1856731165088515e-05,
      "loss": 0.2505,
      "step": 2480
    },
    {
      "epoch": 1.3941769316909294,
      "grad_norm": 3.889514207839966,
      "learning_rate": 1.1815561959654181e-05,
      "loss": 0.2482,
      "step": 2490
    },
    {
      "epoch": 1.3997760358342666,
      "grad_norm": 1.9598402976989746,
      "learning_rate": 1.1774392754219846e-05,
      "loss": 0.2278,
      "step": 2500
    },
    {
      "epoch": 1.4053751399776035,
      "grad_norm": 13.081429481506348,
      "learning_rate": 1.1733223548785509e-05,
      "loss": 0.2747,
      "step": 2510
    },
    {
      "epoch": 1.4109742441209407,
      "grad_norm": 5.871520042419434,
      "learning_rate": 1.1692054343351173e-05,
      "loss": 0.2787,
      "step": 2520
    },
    {
      "epoch": 1.4165733482642777,
      "grad_norm": 6.849419116973877,
      "learning_rate": 1.1650885137916838e-05,
      "loss": 0.2021,
      "step": 2530
    },
    {
      "epoch": 1.4221724524076147,
      "grad_norm": 3.20358943939209,
      "learning_rate": 1.1609715932482504e-05,
      "loss": 0.2607,
      "step": 2540
    },
    {
      "epoch": 1.427771556550952,
      "grad_norm": 6.017261981964111,
      "learning_rate": 1.1568546727048169e-05,
      "loss": 0.2373,
      "step": 2550
    },
    {
      "epoch": 1.4333706606942889,
      "grad_norm": 3.4092190265655518,
      "learning_rate": 1.1527377521613834e-05,
      "loss": 0.1963,
      "step": 2560
    },
    {
      "epoch": 1.4389697648376258,
      "grad_norm": 1.474818229675293,
      "learning_rate": 1.1486208316179498e-05,
      "loss": 0.1538,
      "step": 2570
    },
    {
      "epoch": 1.444568868980963,
      "grad_norm": 9.175993919372559,
      "learning_rate": 1.1445039110745165e-05,
      "loss": 0.1988,
      "step": 2580
    },
    {
      "epoch": 1.4501679731243002,
      "grad_norm": 7.58366060256958,
      "learning_rate": 1.140386990531083e-05,
      "loss": 0.182,
      "step": 2590
    },
    {
      "epoch": 1.4557670772676372,
      "grad_norm": 4.9519453048706055,
      "learning_rate": 1.1366817620419927e-05,
      "loss": 0.1845,
      "step": 2600
    },
    {
      "epoch": 1.4613661814109742,
      "grad_norm": 5.067107200622559,
      "learning_rate": 1.1325648414985593e-05,
      "loss": 0.1753,
      "step": 2610
    },
    {
      "epoch": 1.4669652855543114,
      "grad_norm": 3.5784339904785156,
      "learning_rate": 1.1284479209551256e-05,
      "loss": 0.2363,
      "step": 2620
    },
    {
      "epoch": 1.4725643896976484,
      "grad_norm": 7.685103416442871,
      "learning_rate": 1.1243310004116921e-05,
      "loss": 0.1955,
      "step": 2630
    },
    {
      "epoch": 1.4781634938409853,
      "grad_norm": 5.316217422485352,
      "learning_rate": 1.1202140798682586e-05,
      "loss": 0.2005,
      "step": 2640
    },
    {
      "epoch": 1.4837625979843225,
      "grad_norm": 15.122164726257324,
      "learning_rate": 1.116097159324825e-05,
      "loss": 0.3418,
      "step": 2650
    },
    {
      "epoch": 1.4893617021276595,
      "grad_norm": 6.868546009063721,
      "learning_rate": 1.1119802387813917e-05,
      "loss": 0.1598,
      "step": 2660
    },
    {
      "epoch": 1.4949608062709967,
      "grad_norm": 7.918847560882568,
      "learning_rate": 1.1078633182379581e-05,
      "loss": 0.271,
      "step": 2670
    },
    {
      "epoch": 1.5005599104143337,
      "grad_norm": 4.984613418579102,
      "learning_rate": 1.1037463976945246e-05,
      "loss": 0.2477,
      "step": 2680
    },
    {
      "epoch": 1.5061590145576709,
      "grad_norm": 7.563613414764404,
      "learning_rate": 1.099629477151091e-05,
      "loss": 0.2618,
      "step": 2690
    },
    {
      "epoch": 1.5117581187010078,
      "grad_norm": 3.6244442462921143,
      "learning_rate": 1.0955125566076577e-05,
      "loss": 0.197,
      "step": 2700
    },
    {
      "epoch": 1.5173572228443448,
      "grad_norm": 6.600188732147217,
      "learning_rate": 1.091395636064224e-05,
      "loss": 0.2856,
      "step": 2710
    },
    {
      "epoch": 1.522956326987682,
      "grad_norm": 2.0934786796569824,
      "learning_rate": 1.0872787155207905e-05,
      "loss": 0.1252,
      "step": 2720
    },
    {
      "epoch": 1.528555431131019,
      "grad_norm": 4.3047871589660645,
      "learning_rate": 1.083161794977357e-05,
      "loss": 0.2196,
      "step": 2730
    },
    {
      "epoch": 1.534154535274356,
      "grad_norm": 6.246732711791992,
      "learning_rate": 1.0790448744339234e-05,
      "loss": 0.2749,
      "step": 2740
    },
    {
      "epoch": 1.5397536394176932,
      "grad_norm": 10.456588745117188,
      "learning_rate": 1.07492795389049e-05,
      "loss": 0.248,
      "step": 2750
    },
    {
      "epoch": 1.5453527435610304,
      "grad_norm": 3.646563768386841,
      "learning_rate": 1.0708110333470565e-05,
      "loss": 0.2262,
      "step": 2760
    },
    {
      "epoch": 1.5509518477043673,
      "grad_norm": 5.824949741363525,
      "learning_rate": 1.066694112803623e-05,
      "loss": 0.1861,
      "step": 2770
    },
    {
      "epoch": 1.5565509518477043,
      "grad_norm": 2.4321460723876953,
      "learning_rate": 1.0625771922601894e-05,
      "loss": 0.2664,
      "step": 2780
    },
    {
      "epoch": 1.5621500559910415,
      "grad_norm": 2.7470014095306396,
      "learning_rate": 1.058460271716756e-05,
      "loss": 0.1526,
      "step": 2790
    },
    {
      "epoch": 1.5677491601343785,
      "grad_norm": 6.324165344238281,
      "learning_rate": 1.0543433511733225e-05,
      "loss": 0.211,
      "step": 2800
    },
    {
      "epoch": 1.5733482642777155,
      "grad_norm": 8.65618896484375,
      "learning_rate": 1.0502264306298888e-05,
      "loss": 0.2008,
      "step": 2810
    },
    {
      "epoch": 1.5789473684210527,
      "grad_norm": 2.430802345275879,
      "learning_rate": 1.0461095100864553e-05,
      "loss": 0.2312,
      "step": 2820
    },
    {
      "epoch": 1.5845464725643899,
      "grad_norm": 5.220730304718018,
      "learning_rate": 1.0419925895430218e-05,
      "loss": 0.2035,
      "step": 2830
    },
    {
      "epoch": 1.5901455767077266,
      "grad_norm": 1.6878314018249512,
      "learning_rate": 1.0378756689995884e-05,
      "loss": 0.2403,
      "step": 2840
    },
    {
      "epoch": 1.5957446808510638,
      "grad_norm": 5.813240051269531,
      "learning_rate": 1.0337587484561549e-05,
      "loss": 0.2044,
      "step": 2850
    },
    {
      "epoch": 1.601343784994401,
      "grad_norm": 8.51229190826416,
      "learning_rate": 1.0296418279127213e-05,
      "loss": 0.1795,
      "step": 2860
    },
    {
      "epoch": 1.606942889137738,
      "grad_norm": 4.331172943115234,
      "learning_rate": 1.0255249073692878e-05,
      "loss": 0.1963,
      "step": 2870
    },
    {
      "epoch": 1.612541993281075,
      "grad_norm": 3.7598767280578613,
      "learning_rate": 1.0214079868258545e-05,
      "loss": 0.2107,
      "step": 2880
    },
    {
      "epoch": 1.6181410974244121,
      "grad_norm": 5.555071830749512,
      "learning_rate": 1.017291066282421e-05,
      "loss": 0.2986,
      "step": 2890
    },
    {
      "epoch": 1.6237402015677491,
      "grad_norm": 5.404829978942871,
      "learning_rate": 1.0131741457389874e-05,
      "loss": 0.2155,
      "step": 2900
    },
    {
      "epoch": 1.629339305711086,
      "grad_norm": 7.509997367858887,
      "learning_rate": 1.0090572251955537e-05,
      "loss": 0.1731,
      "step": 2910
    },
    {
      "epoch": 1.6349384098544233,
      "grad_norm": 4.789267063140869,
      "learning_rate": 1.0049403046521202e-05,
      "loss": 0.2404,
      "step": 2920
    },
    {
      "epoch": 1.6405375139977605,
      "grad_norm": 2.109879970550537,
      "learning_rate": 1.0008233841086868e-05,
      "loss": 0.1979,
      "step": 2930
    },
    {
      "epoch": 1.6461366181410975,
      "grad_norm": 12.609392166137695,
      "learning_rate": 9.967064635652533e-06,
      "loss": 0.1395,
      "step": 2940
    },
    {
      "epoch": 1.6517357222844344,
      "grad_norm": 7.507476329803467,
      "learning_rate": 9.925895430218197e-06,
      "loss": 0.2193,
      "step": 2950
    },
    {
      "epoch": 1.6573348264277716,
      "grad_norm": 6.080920219421387,
      "learning_rate": 9.884726224783862e-06,
      "loss": 0.2621,
      "step": 2960
    },
    {
      "epoch": 1.6629339305711086,
      "grad_norm": 5.591540813446045,
      "learning_rate": 9.843557019349528e-06,
      "loss": 0.1913,
      "step": 2970
    },
    {
      "epoch": 1.6685330347144456,
      "grad_norm": 5.79482364654541,
      "learning_rate": 9.802387813915191e-06,
      "loss": 0.246,
      "step": 2980
    },
    {
      "epoch": 1.6741321388577828,
      "grad_norm": 8.143056869506836,
      "learning_rate": 9.761218608480858e-06,
      "loss": 0.2067,
      "step": 2990
    },
    {
      "epoch": 1.67973124300112,
      "grad_norm": 2.734837293624878,
      "learning_rate": 9.720049403046522e-06,
      "loss": 0.1819,
      "step": 3000
    },
    {
      "epoch": 1.6853303471444567,
      "grad_norm": 5.7450032234191895,
      "learning_rate": 9.678880197612187e-06,
      "loss": 0.177,
      "step": 3010
    },
    {
      "epoch": 1.690929451287794,
      "grad_norm": 4.821717262268066,
      "learning_rate": 9.637710992177852e-06,
      "loss": 0.2045,
      "step": 3020
    },
    {
      "epoch": 1.6965285554311311,
      "grad_norm": 5.035658836364746,
      "learning_rate": 9.596541786743516e-06,
      "loss": 0.237,
      "step": 3030
    },
    {
      "epoch": 1.702127659574468,
      "grad_norm": 5.080459117889404,
      "learning_rate": 9.555372581309181e-06,
      "loss": 0.1701,
      "step": 3040
    },
    {
      "epoch": 1.707726763717805,
      "grad_norm": 5.880096435546875,
      "learning_rate": 9.514203375874846e-06,
      "loss": 0.219,
      "step": 3050
    },
    {
      "epoch": 1.7133258678611423,
      "grad_norm": 3.106502056121826,
      "learning_rate": 9.473034170440512e-06,
      "loss": 0.1315,
      "step": 3060
    },
    {
      "epoch": 1.7189249720044792,
      "grad_norm": 4.437565326690674,
      "learning_rate": 9.431864965006177e-06,
      "loss": 0.1919,
      "step": 3070
    },
    {
      "epoch": 1.7245240761478162,
      "grad_norm": 7.188442230224609,
      "learning_rate": 9.390695759571841e-06,
      "loss": 0.2178,
      "step": 3080
    },
    {
      "epoch": 1.7301231802911534,
      "grad_norm": 5.76331090927124,
      "learning_rate": 9.349526554137506e-06,
      "loss": 0.2578,
      "step": 3090
    },
    {
      "epoch": 1.7357222844344906,
      "grad_norm": 1.3206897974014282,
      "learning_rate": 9.30835734870317e-06,
      "loss": 0.1941,
      "step": 3100
    },
    {
      "epoch": 1.7413213885778276,
      "grad_norm": 10.526055335998535,
      "learning_rate": 9.267188143268835e-06,
      "loss": 0.2499,
      "step": 3110
    },
    {
      "epoch": 1.7469204927211646,
      "grad_norm": 4.056236267089844,
      "learning_rate": 9.226018937834502e-06,
      "loss": 0.1871,
      "step": 3120
    },
    {
      "epoch": 1.7525195968645018,
      "grad_norm": 3.1320641040802,
      "learning_rate": 9.184849732400165e-06,
      "loss": 0.198,
      "step": 3130
    },
    {
      "epoch": 1.7581187010078387,
      "grad_norm": 3.586918830871582,
      "learning_rate": 9.14368052696583e-06,
      "loss": 0.1893,
      "step": 3140
    },
    {
      "epoch": 1.7637178051511757,
      "grad_norm": 2.208218812942505,
      "learning_rate": 9.102511321531496e-06,
      "loss": 0.2014,
      "step": 3150
    },
    {
      "epoch": 1.769316909294513,
      "grad_norm": 6.256646633148193,
      "learning_rate": 9.06134211609716e-06,
      "loss": 0.261,
      "step": 3160
    },
    {
      "epoch": 1.77491601343785,
      "grad_norm": 5.537729740142822,
      "learning_rate": 9.020172910662825e-06,
      "loss": 0.2159,
      "step": 3170
    },
    {
      "epoch": 1.7805151175811869,
      "grad_norm": 5.081045150756836,
      "learning_rate": 8.97900370522849e-06,
      "loss": 0.2506,
      "step": 3180
    },
    {
      "epoch": 1.786114221724524,
      "grad_norm": 4.645401954650879,
      "learning_rate": 8.937834499794154e-06,
      "loss": 0.2044,
      "step": 3190
    },
    {
      "epoch": 1.7917133258678613,
      "grad_norm": 5.0553998947143555,
      "learning_rate": 8.896665294359819e-06,
      "loss": 0.2132,
      "step": 3200
    },
    {
      "epoch": 1.7973124300111982,
      "grad_norm": 7.585970401763916,
      "learning_rate": 8.855496088925486e-06,
      "loss": 0.2425,
      "step": 3210
    },
    {
      "epoch": 1.8029115341545352,
      "grad_norm": 11.790304183959961,
      "learning_rate": 8.814326883491148e-06,
      "loss": 0.1905,
      "step": 3220
    },
    {
      "epoch": 1.8085106382978724,
      "grad_norm": 12.157065391540527,
      "learning_rate": 8.773157678056813e-06,
      "loss": 0.2682,
      "step": 3230
    },
    {
      "epoch": 1.8141097424412094,
      "grad_norm": 5.145879745483398,
      "learning_rate": 8.73198847262248e-06,
      "loss": 0.1496,
      "step": 3240
    },
    {
      "epoch": 1.8197088465845463,
      "grad_norm": 6.031256198883057,
      "learning_rate": 8.690819267188144e-06,
      "loss": 0.2133,
      "step": 3250
    },
    {
      "epoch": 1.8253079507278835,
      "grad_norm": 14.442194938659668,
      "learning_rate": 8.649650061753809e-06,
      "loss": 0.1907,
      "step": 3260
    },
    {
      "epoch": 1.8309070548712207,
      "grad_norm": 4.922250747680664,
      "learning_rate": 8.608480856319474e-06,
      "loss": 0.1784,
      "step": 3270
    },
    {
      "epoch": 1.8365061590145577,
      "grad_norm": 7.210888862609863,
      "learning_rate": 8.567311650885138e-06,
      "loss": 0.274,
      "step": 3280
    },
    {
      "epoch": 1.8421052631578947,
      "grad_norm": 4.158113479614258,
      "learning_rate": 8.526142445450803e-06,
      "loss": 0.1921,
      "step": 3290
    },
    {
      "epoch": 1.8477043673012319,
      "grad_norm": 3.5381367206573486,
      "learning_rate": 8.48497324001647e-06,
      "loss": 0.2306,
      "step": 3300
    },
    {
      "epoch": 1.8533034714445689,
      "grad_norm": 3.876819372177124,
      "learning_rate": 8.443804034582134e-06,
      "loss": 0.21,
      "step": 3310
    },
    {
      "epoch": 1.8589025755879058,
      "grad_norm": 8.401463508605957,
      "learning_rate": 8.402634829147797e-06,
      "loss": 0.1646,
      "step": 3320
    },
    {
      "epoch": 1.864501679731243,
      "grad_norm": 4.79644775390625,
      "learning_rate": 8.361465623713463e-06,
      "loss": 0.1625,
      "step": 3330
    },
    {
      "epoch": 1.8701007838745802,
      "grad_norm": 8.02918815612793,
      "learning_rate": 8.320296418279128e-06,
      "loss": 0.1806,
      "step": 3340
    },
    {
      "epoch": 1.875699888017917,
      "grad_norm": 7.698041915893555,
      "learning_rate": 8.279127212844793e-06,
      "loss": 0.2589,
      "step": 3350
    },
    {
      "epoch": 1.8812989921612542,
      "grad_norm": 3.0799710750579834,
      "learning_rate": 8.237958007410457e-06,
      "loss": 0.1749,
      "step": 3360
    },
    {
      "epoch": 1.8868980963045914,
      "grad_norm": 8.602160453796387,
      "learning_rate": 8.196788801976122e-06,
      "loss": 0.2033,
      "step": 3370
    },
    {
      "epoch": 1.8924972004479284,
      "grad_norm": 4.744528770446777,
      "learning_rate": 8.155619596541787e-06,
      "loss": 0.2258,
      "step": 3380
    },
    {
      "epoch": 1.8980963045912653,
      "grad_norm": 6.037196636199951,
      "learning_rate": 8.114450391107453e-06,
      "loss": 0.2143,
      "step": 3390
    },
    {
      "epoch": 1.9036954087346025,
      "grad_norm": 3.4272968769073486,
      "learning_rate": 8.073281185673118e-06,
      "loss": 0.1805,
      "step": 3400
    },
    {
      "epoch": 1.9092945128779395,
      "grad_norm": 2.158677101135254,
      "learning_rate": 8.032111980238782e-06,
      "loss": 0.2108,
      "step": 3410
    },
    {
      "epoch": 1.9148936170212765,
      "grad_norm": 3.2373926639556885,
      "learning_rate": 7.990942774804447e-06,
      "loss": 0.1841,
      "step": 3420
    },
    {
      "epoch": 1.9204927211646137,
      "grad_norm": 5.206461429595947,
      "learning_rate": 7.949773569370112e-06,
      "loss": 0.1595,
      "step": 3430
    },
    {
      "epoch": 1.9260918253079509,
      "grad_norm": 9.050043106079102,
      "learning_rate": 7.908604363935776e-06,
      "loss": 0.2538,
      "step": 3440
    },
    {
      "epoch": 1.9316909294512878,
      "grad_norm": 4.394134998321533,
      "learning_rate": 7.867435158501441e-06,
      "loss": 0.1778,
      "step": 3450
    },
    {
      "epoch": 1.9372900335946248,
      "grad_norm": 5.9045820236206055,
      "learning_rate": 7.826265953067106e-06,
      "loss": 0.2546,
      "step": 3460
    },
    {
      "epoch": 1.942889137737962,
      "grad_norm": 2.4959352016448975,
      "learning_rate": 7.78509674763277e-06,
      "loss": 0.2135,
      "step": 3470
    },
    {
      "epoch": 1.948488241881299,
      "grad_norm": 4.885079860687256,
      "learning_rate": 7.743927542198437e-06,
      "loss": 0.177,
      "step": 3480
    },
    {
      "epoch": 1.954087346024636,
      "grad_norm": 3.828329563140869,
      "learning_rate": 7.702758336764101e-06,
      "loss": 0.2098,
      "step": 3490
    },
    {
      "epoch": 1.9596864501679732,
      "grad_norm": 5.504137992858887,
      "learning_rate": 7.661589131329766e-06,
      "loss": 0.2002,
      "step": 3500
    },
    {
      "epoch": 1.9652855543113104,
      "grad_norm": 5.789626121520996,
      "learning_rate": 7.62041992589543e-06,
      "loss": 0.1994,
      "step": 3510
    },
    {
      "epoch": 1.970884658454647,
      "grad_norm": 6.6734700202941895,
      "learning_rate": 7.5792507204610955e-06,
      "loss": 0.2006,
      "step": 3520
    },
    {
      "epoch": 1.9764837625979843,
      "grad_norm": 2.9629905223846436,
      "learning_rate": 7.53808151502676e-06,
      "loss": 0.243,
      "step": 3530
    },
    {
      "epoch": 1.9820828667413215,
      "grad_norm": 6.377590656280518,
      "learning_rate": 7.496912309592426e-06,
      "loss": 0.1985,
      "step": 3540
    },
    {
      "epoch": 1.9876819708846585,
      "grad_norm": 3.358290910720825,
      "learning_rate": 7.45574310415809e-06,
      "loss": 0.1431,
      "step": 3550
    },
    {
      "epoch": 1.9932810750279955,
      "grad_norm": 5.771503448486328,
      "learning_rate": 7.414573898723755e-06,
      "loss": 0.2365,
      "step": 3560
    },
    {
      "epoch": 1.9988801791713326,
      "grad_norm": 6.108245849609375,
      "learning_rate": 7.37340469328942e-06,
      "loss": 0.1458,
      "step": 3570
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9132138857782754,
      "eval_f1": 0.9136425080816502,
      "eval_loss": 0.24290375411510468,
      "eval_precision": 0.9168447858194493,
      "eval_recall": 0.9132138857782754,
      "eval_runtime": 503.3301,
      "eval_samples_per_second": 28.387,
      "eval_steps_per_second": 0.445,
      "step": 3572
    },
    {
      "epoch": 2.00447928331467,
      "grad_norm": 5.097783088684082,
      "learning_rate": 7.332235487855085e-06,
      "loss": 0.1678,
      "step": 3580
    },
    {
      "epoch": 2.0100783874580066,
      "grad_norm": 4.832151412963867,
      "learning_rate": 7.29106628242075e-06,
      "loss": 0.221,
      "step": 3590
    },
    {
      "epoch": 2.015677491601344,
      "grad_norm": 11.364115715026855,
      "learning_rate": 7.249897076986415e-06,
      "loss": 0.2206,
      "step": 3600
    },
    {
      "epoch": 2.021276595744681,
      "grad_norm": 4.06181001663208,
      "learning_rate": 7.208727871552079e-06,
      "loss": 0.1835,
      "step": 3610
    },
    {
      "epoch": 2.0268756998880177,
      "grad_norm": 8.779810905456543,
      "learning_rate": 7.167558666117744e-06,
      "loss": 0.1998,
      "step": 3620
    },
    {
      "epoch": 2.032474804031355,
      "grad_norm": 8.024197578430176,
      "learning_rate": 7.1263894606834094e-06,
      "loss": 0.1691,
      "step": 3630
    },
    {
      "epoch": 2.038073908174692,
      "grad_norm": 6.720316410064697,
      "learning_rate": 7.085220255249075e-06,
      "loss": 0.1239,
      "step": 3640
    },
    {
      "epoch": 2.0436730123180293,
      "grad_norm": 2.686237335205078,
      "learning_rate": 7.04405104981474e-06,
      "loss": 0.1647,
      "step": 3650
    },
    {
      "epoch": 2.049272116461366,
      "grad_norm": 6.235955715179443,
      "learning_rate": 7.0028818443804035e-06,
      "loss": 0.1405,
      "step": 3660
    },
    {
      "epoch": 2.0548712206047033,
      "grad_norm": 4.942488670349121,
      "learning_rate": 6.961712638946069e-06,
      "loss": 0.1886,
      "step": 3670
    },
    {
      "epoch": 2.0604703247480405,
      "grad_norm": 4.916800022125244,
      "learning_rate": 6.920543433511734e-06,
      "loss": 0.1972,
      "step": 3680
    },
    {
      "epoch": 2.0660694288913772,
      "grad_norm": 8.90701961517334,
      "learning_rate": 6.879374228077399e-06,
      "loss": 0.196,
      "step": 3690
    },
    {
      "epoch": 2.0716685330347144,
      "grad_norm": 4.9587626457214355,
      "learning_rate": 6.838205022643064e-06,
      "loss": 0.2156,
      "step": 3700
    },
    {
      "epoch": 2.0772676371780516,
      "grad_norm": 1.6549148559570312,
      "learning_rate": 6.797035817208728e-06,
      "loss": 0.1892,
      "step": 3710
    },
    {
      "epoch": 2.0828667413213884,
      "grad_norm": 4.218588829040527,
      "learning_rate": 6.755866611774393e-06,
      "loss": 0.1446,
      "step": 3720
    },
    {
      "epoch": 2.0884658454647256,
      "grad_norm": 3.1872150897979736,
      "learning_rate": 6.714697406340059e-06,
      "loss": 0.1593,
      "step": 3730
    },
    {
      "epoch": 2.0940649496080628,
      "grad_norm": 9.285433769226074,
      "learning_rate": 6.673528200905723e-06,
      "loss": 0.1899,
      "step": 3740
    },
    {
      "epoch": 2.0996640537514,
      "grad_norm": 6.662360668182373,
      "learning_rate": 6.632358995471387e-06,
      "loss": 0.1675,
      "step": 3750
    },
    {
      "epoch": 2.1052631578947367,
      "grad_norm": 5.334203720092773,
      "learning_rate": 6.591189790037053e-06,
      "loss": 0.1379,
      "step": 3760
    },
    {
      "epoch": 2.110862262038074,
      "grad_norm": 4.42915153503418,
      "learning_rate": 6.550020584602717e-06,
      "loss": 0.169,
      "step": 3770
    },
    {
      "epoch": 2.116461366181411,
      "grad_norm": 11.241613388061523,
      "learning_rate": 6.508851379168383e-06,
      "loss": 0.2002,
      "step": 3780
    },
    {
      "epoch": 2.122060470324748,
      "grad_norm": 3.164541482925415,
      "learning_rate": 6.467682173734048e-06,
      "loss": 0.1669,
      "step": 3790
    },
    {
      "epoch": 2.127659574468085,
      "grad_norm": 2.955850839614868,
      "learning_rate": 6.426512968299711e-06,
      "loss": 0.1276,
      "step": 3800
    },
    {
      "epoch": 2.1332586786114223,
      "grad_norm": 7.654098987579346,
      "learning_rate": 6.385343762865377e-06,
      "loss": 0.1658,
      "step": 3810
    },
    {
      "epoch": 2.1388577827547595,
      "grad_norm": 1.7426410913467407,
      "learning_rate": 6.3441745574310425e-06,
      "loss": 0.1647,
      "step": 3820
    },
    {
      "epoch": 2.144456886898096,
      "grad_norm": 6.825402736663818,
      "learning_rate": 6.303005351996707e-06,
      "loss": 0.1575,
      "step": 3830
    },
    {
      "epoch": 2.1500559910414334,
      "grad_norm": 2.791855573654175,
      "learning_rate": 6.261836146562373e-06,
      "loss": 0.1518,
      "step": 3840
    },
    {
      "epoch": 2.1556550951847706,
      "grad_norm": 3.7212743759155273,
      "learning_rate": 6.2206669411280365e-06,
      "loss": 0.1744,
      "step": 3850
    },
    {
      "epoch": 2.1612541993281074,
      "grad_norm": 4.602931976318359,
      "learning_rate": 6.179497735693701e-06,
      "loss": 0.1672,
      "step": 3860
    },
    {
      "epoch": 2.1668533034714446,
      "grad_norm": 3.4925289154052734,
      "learning_rate": 6.138328530259367e-06,
      "loss": 0.1346,
      "step": 3870
    },
    {
      "epoch": 2.1724524076147818,
      "grad_norm": 4.027843475341797,
      "learning_rate": 6.097159324825031e-06,
      "loss": 0.2064,
      "step": 3880
    },
    {
      "epoch": 2.1780515117581185,
      "grad_norm": 5.658145904541016,
      "learning_rate": 6.055990119390697e-06,
      "loss": 0.1962,
      "step": 3890
    },
    {
      "epoch": 2.1836506159014557,
      "grad_norm": 4.9985175132751465,
      "learning_rate": 6.014820913956361e-06,
      "loss": 0.1508,
      "step": 3900
    },
    {
      "epoch": 2.189249720044793,
      "grad_norm": 7.84805154800415,
      "learning_rate": 5.973651708522026e-06,
      "loss": 0.2151,
      "step": 3910
    },
    {
      "epoch": 2.19484882418813,
      "grad_norm": 4.441728115081787,
      "learning_rate": 5.932482503087691e-06,
      "loss": 0.1727,
      "step": 3920
    },
    {
      "epoch": 2.200447928331467,
      "grad_norm": 6.802459239959717,
      "learning_rate": 5.891313297653356e-06,
      "loss": 0.1153,
      "step": 3930
    },
    {
      "epoch": 2.206047032474804,
      "grad_norm": 9.863030433654785,
      "learning_rate": 5.850144092219021e-06,
      "loss": 0.1525,
      "step": 3940
    },
    {
      "epoch": 2.2116461366181412,
      "grad_norm": 6.265470504760742,
      "learning_rate": 5.808974886784685e-06,
      "loss": 0.1875,
      "step": 3950
    },
    {
      "epoch": 2.217245240761478,
      "grad_norm": 3.43792462348938,
      "learning_rate": 5.7678056813503504e-06,
      "loss": 0.1922,
      "step": 3960
    },
    {
      "epoch": 2.222844344904815,
      "grad_norm": 3.2398200035095215,
      "learning_rate": 5.726636475916015e-06,
      "loss": 0.1805,
      "step": 3970
    },
    {
      "epoch": 2.2284434490481524,
      "grad_norm": 3.5055298805236816,
      "learning_rate": 5.685467270481681e-06,
      "loss": 0.2295,
      "step": 3980
    },
    {
      "epoch": 2.2340425531914896,
      "grad_norm": 5.865468978881836,
      "learning_rate": 5.644298065047345e-06,
      "loss": 0.2094,
      "step": 3990
    },
    {
      "epoch": 2.2396416573348263,
      "grad_norm": 10.810385704040527,
      "learning_rate": 5.60312885961301e-06,
      "loss": 0.1617,
      "step": 4000
    },
    {
      "epoch": 2.2452407614781635,
      "grad_norm": 4.472800254821777,
      "learning_rate": 5.561959654178675e-06,
      "loss": 0.1442,
      "step": 4010
    },
    {
      "epoch": 2.2508398656215007,
      "grad_norm": 2.1384060382843018,
      "learning_rate": 5.52079044874434e-06,
      "loss": 0.1655,
      "step": 4020
    },
    {
      "epoch": 2.2564389697648375,
      "grad_norm": 5.284766674041748,
      "learning_rate": 5.479621243310005e-06,
      "loss": 0.1537,
      "step": 4030
    },
    {
      "epoch": 2.2620380739081747,
      "grad_norm": 2.2696776390075684,
      "learning_rate": 5.43845203787567e-06,
      "loss": 0.1839,
      "step": 4040
    },
    {
      "epoch": 2.267637178051512,
      "grad_norm": 9.854657173156738,
      "learning_rate": 5.397282832441334e-06,
      "loss": 0.1559,
      "step": 4050
    },
    {
      "epoch": 2.2732362821948486,
      "grad_norm": 5.315471649169922,
      "learning_rate": 5.356113627006999e-06,
      "loss": 0.2251,
      "step": 4060
    },
    {
      "epoch": 2.278835386338186,
      "grad_norm": 7.688543319702148,
      "learning_rate": 5.314944421572664e-06,
      "loss": 0.1877,
      "step": 4070
    },
    {
      "epoch": 2.284434490481523,
      "grad_norm": 2.628641366958618,
      "learning_rate": 5.273775216138329e-06,
      "loss": 0.2322,
      "step": 4080
    },
    {
      "epoch": 2.29003359462486,
      "grad_norm": 1.3863991498947144,
      "learning_rate": 5.232606010703994e-06,
      "loss": 0.1703,
      "step": 4090
    },
    {
      "epoch": 2.295632698768197,
      "grad_norm": 2.8887579441070557,
      "learning_rate": 5.191436805269658e-06,
      "loss": 0.1631,
      "step": 4100
    },
    {
      "epoch": 2.301231802911534,
      "grad_norm": 3.8106849193573,
      "learning_rate": 5.150267599835324e-06,
      "loss": 0.1774,
      "step": 4110
    },
    {
      "epoch": 2.3068309070548714,
      "grad_norm": 5.584771156311035,
      "learning_rate": 5.109098394400989e-06,
      "loss": 0.1844,
      "step": 4120
    },
    {
      "epoch": 2.312430011198208,
      "grad_norm": 2.4408345222473145,
      "learning_rate": 5.067929188966654e-06,
      "loss": 0.136,
      "step": 4130
    },
    {
      "epoch": 2.3180291153415453,
      "grad_norm": 4.293814659118652,
      "learning_rate": 5.026759983532318e-06,
      "loss": 0.1445,
      "step": 4140
    },
    {
      "epoch": 2.3236282194848825,
      "grad_norm": 9.10101318359375,
      "learning_rate": 4.985590778097983e-06,
      "loss": 0.1399,
      "step": 4150
    },
    {
      "epoch": 2.3292273236282197,
      "grad_norm": 5.2885422706604,
      "learning_rate": 4.944421572663648e-06,
      "loss": 0.1809,
      "step": 4160
    },
    {
      "epoch": 2.3348264277715565,
      "grad_norm": 3.8807547092437744,
      "learning_rate": 4.903252367229313e-06,
      "loss": 0.1732,
      "step": 4170
    },
    {
      "epoch": 2.3404255319148937,
      "grad_norm": 2.6335058212280273,
      "learning_rate": 4.8620831617949775e-06,
      "loss": 0.1741,
      "step": 4180
    },
    {
      "epoch": 2.346024636058231,
      "grad_norm": 11.051513671875,
      "learning_rate": 4.820913956360643e-06,
      "loss": 0.1859,
      "step": 4190
    },
    {
      "epoch": 2.3516237402015676,
      "grad_norm": 2.9888792037963867,
      "learning_rate": 4.779744750926308e-06,
      "loss": 0.2211,
      "step": 4200
    },
    {
      "epoch": 2.357222844344905,
      "grad_norm": 6.197791576385498,
      "learning_rate": 4.738575545491972e-06,
      "loss": 0.2136,
      "step": 4210
    },
    {
      "epoch": 2.362821948488242,
      "grad_norm": 4.192415714263916,
      "learning_rate": 4.697406340057638e-06,
      "loss": 0.1306,
      "step": 4220
    },
    {
      "epoch": 2.3684210526315788,
      "grad_norm": 2.1453139781951904,
      "learning_rate": 4.656237134623302e-06,
      "loss": 0.2141,
      "step": 4230
    },
    {
      "epoch": 2.374020156774916,
      "grad_norm": 8.382570266723633,
      "learning_rate": 4.615067929188967e-06,
      "loss": 0.1677,
      "step": 4240
    },
    {
      "epoch": 2.379619260918253,
      "grad_norm": 4.636651515960693,
      "learning_rate": 4.573898723754632e-06,
      "loss": 0.0896,
      "step": 4250
    },
    {
      "epoch": 2.38521836506159,
      "grad_norm": 5.035698890686035,
      "learning_rate": 4.5327295183202966e-06,
      "loss": 0.1337,
      "step": 4260
    },
    {
      "epoch": 2.390817469204927,
      "grad_norm": 6.510598182678223,
      "learning_rate": 4.491560312885961e-06,
      "loss": 0.2081,
      "step": 4270
    },
    {
      "epoch": 2.3964165733482643,
      "grad_norm": 6.3340744972229,
      "learning_rate": 4.450391107451627e-06,
      "loss": 0.1929,
      "step": 4280
    },
    {
      "epoch": 2.4020156774916015,
      "grad_norm": 3.342604875564575,
      "learning_rate": 4.4092219020172914e-06,
      "loss": 0.1653,
      "step": 4290
    },
    {
      "epoch": 2.4076147816349383,
      "grad_norm": 4.763153076171875,
      "learning_rate": 4.368052696582956e-06,
      "loss": 0.2103,
      "step": 4300
    },
    {
      "epoch": 2.4132138857782754,
      "grad_norm": 8.760075569152832,
      "learning_rate": 4.326883491148622e-06,
      "loss": 0.1804,
      "step": 4310
    },
    {
      "epoch": 2.4188129899216126,
      "grad_norm": 6.438909530639648,
      "learning_rate": 4.2857142857142855e-06,
      "loss": 0.1782,
      "step": 4320
    },
    {
      "epoch": 2.42441209406495,
      "grad_norm": 6.958805561065674,
      "learning_rate": 4.244545080279951e-06,
      "loss": 0.2135,
      "step": 4330
    },
    {
      "epoch": 2.4300111982082866,
      "grad_norm": 3.5165534019470215,
      "learning_rate": 4.203375874845616e-06,
      "loss": 0.1242,
      "step": 4340
    },
    {
      "epoch": 2.435610302351624,
      "grad_norm": 7.391629695892334,
      "learning_rate": 4.16220666941128e-06,
      "loss": 0.195,
      "step": 4350
    },
    {
      "epoch": 2.441209406494961,
      "grad_norm": 8.145057678222656,
      "learning_rate": 4.121037463976946e-06,
      "loss": 0.1869,
      "step": 4360
    },
    {
      "epoch": 2.4468085106382977,
      "grad_norm": 2.431469202041626,
      "learning_rate": 4.0798682585426105e-06,
      "loss": 0.1937,
      "step": 4370
    },
    {
      "epoch": 2.452407614781635,
      "grad_norm": 2.575847625732422,
      "learning_rate": 4.038699053108275e-06,
      "loss": 0.1402,
      "step": 4380
    },
    {
      "epoch": 2.458006718924972,
      "grad_norm": 5.687325954437256,
      "learning_rate": 3.997529847673941e-06,
      "loss": 0.1769,
      "step": 4390
    },
    {
      "epoch": 2.463605823068309,
      "grad_norm": 4.341343402862549,
      "learning_rate": 3.956360642239605e-06,
      "loss": 0.1815,
      "step": 4400
    },
    {
      "epoch": 2.469204927211646,
      "grad_norm": 4.088456630706787,
      "learning_rate": 3.91519143680527e-06,
      "loss": 0.1821,
      "step": 4410
    },
    {
      "epoch": 2.4748040313549833,
      "grad_norm": 4.425020694732666,
      "learning_rate": 3.874022231370935e-06,
      "loss": 0.1362,
      "step": 4420
    },
    {
      "epoch": 2.48040313549832,
      "grad_norm": 3.01265549659729,
      "learning_rate": 3.832853025936599e-06,
      "loss": 0.1801,
      "step": 4430
    },
    {
      "epoch": 2.4860022396416572,
      "grad_norm": 6.227992057800293,
      "learning_rate": 3.7916838205022645e-06,
      "loss": 0.2204,
      "step": 4440
    },
    {
      "epoch": 2.4916013437849944,
      "grad_norm": 6.4144697189331055,
      "learning_rate": 3.7505146150679296e-06,
      "loss": 0.1718,
      "step": 4450
    },
    {
      "epoch": 2.4972004479283316,
      "grad_norm": 7.9325761795043945,
      "learning_rate": 3.7093454096335947e-06,
      "loss": 0.1404,
      "step": 4460
    },
    {
      "epoch": 2.5027995520716684,
      "grad_norm": 1.715587854385376,
      "learning_rate": 3.668176204199259e-06,
      "loss": 0.1657,
      "step": 4470
    },
    {
      "epoch": 2.5083986562150056,
      "grad_norm": 4.123271942138672,
      "learning_rate": 3.627006998764924e-06,
      "loss": 0.1837,
      "step": 4480
    },
    {
      "epoch": 2.5139977603583428,
      "grad_norm": 11.126924514770508,
      "learning_rate": 3.5858377933305887e-06,
      "loss": 0.1816,
      "step": 4490
    },
    {
      "epoch": 2.51959686450168,
      "grad_norm": 6.2312912940979,
      "learning_rate": 3.544668587896254e-06,
      "loss": 0.1752,
      "step": 4500
    },
    {
      "epoch": 2.5251959686450167,
      "grad_norm": 4.312646389007568,
      "learning_rate": 3.503499382461919e-06,
      "loss": 0.2067,
      "step": 4510
    },
    {
      "epoch": 2.530795072788354,
      "grad_norm": 3.1021103858947754,
      "learning_rate": 3.4623301770275836e-06,
      "loss": 0.1192,
      "step": 4520
    },
    {
      "epoch": 2.536394176931691,
      "grad_norm": 2.7085154056549072,
      "learning_rate": 3.4211609715932487e-06,
      "loss": 0.1112,
      "step": 4530
    },
    {
      "epoch": 2.541993281075028,
      "grad_norm": 4.381242275238037,
      "learning_rate": 3.3799917661589134e-06,
      "loss": 0.176,
      "step": 4540
    },
    {
      "epoch": 2.547592385218365,
      "grad_norm": 5.317070484161377,
      "learning_rate": 3.3388225607245785e-06,
      "loss": 0.1517,
      "step": 4550
    },
    {
      "epoch": 2.5531914893617023,
      "grad_norm": 2.8826398849487305,
      "learning_rate": 3.2976533552902436e-06,
      "loss": 0.1397,
      "step": 4560
    },
    {
      "epoch": 2.558790593505039,
      "grad_norm": 2.2341015338897705,
      "learning_rate": 3.256484149855908e-06,
      "loss": 0.1671,
      "step": 4570
    },
    {
      "epoch": 2.564389697648376,
      "grad_norm": 6.2912116050720215,
      "learning_rate": 3.215314944421573e-06,
      "loss": 0.1928,
      "step": 4580
    },
    {
      "epoch": 2.5699888017917134,
      "grad_norm": 6.310832500457764,
      "learning_rate": 3.1741457389872376e-06,
      "loss": 0.1444,
      "step": 4590
    },
    {
      "epoch": 2.57558790593505,
      "grad_norm": 5.619410991668701,
      "learning_rate": 3.1329765335529027e-06,
      "loss": 0.2308,
      "step": 4600
    },
    {
      "epoch": 2.5811870100783874,
      "grad_norm": 6.117985725402832,
      "learning_rate": 3.0918073281185673e-06,
      "loss": 0.1844,
      "step": 4610
    },
    {
      "epoch": 2.5867861142217246,
      "grad_norm": 5.990472316741943,
      "learning_rate": 3.0506381226842324e-06,
      "loss": 0.1333,
      "step": 4620
    },
    {
      "epoch": 2.5923852183650617,
      "grad_norm": 3.9915597438812256,
      "learning_rate": 3.0094689172498975e-06,
      "loss": 0.1283,
      "step": 4630
    },
    {
      "epoch": 2.5979843225083985,
      "grad_norm": 4.6247053146362305,
      "learning_rate": 2.9682997118155622e-06,
      "loss": 0.216,
      "step": 4640
    },
    {
      "epoch": 2.6035834266517357,
      "grad_norm": 7.3812689781188965,
      "learning_rate": 2.9271305063812273e-06,
      "loss": 0.2426,
      "step": 4650
    },
    {
      "epoch": 2.609182530795073,
      "grad_norm": 2.258265256881714,
      "learning_rate": 2.8859613009468916e-06,
      "loss": 0.1723,
      "step": 4660
    },
    {
      "epoch": 2.61478163493841,
      "grad_norm": 8.345807075500488,
      "learning_rate": 2.8447920955125567e-06,
      "loss": 0.1813,
      "step": 4670
    },
    {
      "epoch": 2.620380739081747,
      "grad_norm": 5.283729553222656,
      "learning_rate": 2.803622890078222e-06,
      "loss": 0.1741,
      "step": 4680
    },
    {
      "epoch": 2.625979843225084,
      "grad_norm": 4.905772686004639,
      "learning_rate": 2.7624536846438864e-06,
      "loss": 0.1888,
      "step": 4690
    },
    {
      "epoch": 2.6315789473684212,
      "grad_norm": 4.483362674713135,
      "learning_rate": 2.7212844792095515e-06,
      "loss": 0.1668,
      "step": 4700
    },
    {
      "epoch": 2.637178051511758,
      "grad_norm": 7.104710578918457,
      "learning_rate": 2.680115273775216e-06,
      "loss": 0.1461,
      "step": 4710
    },
    {
      "epoch": 2.642777155655095,
      "grad_norm": 10.026653289794922,
      "learning_rate": 2.6389460683408813e-06,
      "loss": 0.2281,
      "step": 4720
    },
    {
      "epoch": 2.6483762597984324,
      "grad_norm": 5.84870719909668,
      "learning_rate": 2.597776862906546e-06,
      "loss": 0.2072,
      "step": 4730
    },
    {
      "epoch": 2.653975363941769,
      "grad_norm": 5.333673477172852,
      "learning_rate": 2.556607657472211e-06,
      "loss": 0.1753,
      "step": 4740
    },
    {
      "epoch": 2.6595744680851063,
      "grad_norm": 7.526947975158691,
      "learning_rate": 2.515438452037876e-06,
      "loss": 0.2262,
      "step": 4750
    },
    {
      "epoch": 2.6651735722284435,
      "grad_norm": 9.496591567993164,
      "learning_rate": 2.4742692466035404e-06,
      "loss": 0.1047,
      "step": 4760
    },
    {
      "epoch": 2.6707726763717803,
      "grad_norm": 8.986213684082031,
      "learning_rate": 2.433100041169206e-06,
      "loss": 0.1837,
      "step": 4770
    },
    {
      "epoch": 2.6763717805151175,
      "grad_norm": 7.553881645202637,
      "learning_rate": 2.3919308357348706e-06,
      "loss": 0.1973,
      "step": 4780
    },
    {
      "epoch": 2.6819708846584547,
      "grad_norm": 10.498543739318848,
      "learning_rate": 2.3507616303005353e-06,
      "loss": 0.1636,
      "step": 4790
    },
    {
      "epoch": 2.687569988801792,
      "grad_norm": 8.363240242004395,
      "learning_rate": 2.3095924248662004e-06,
      "loss": 0.1761,
      "step": 4800
    },
    {
      "epoch": 2.6931690929451286,
      "grad_norm": 5.700252532958984,
      "learning_rate": 2.268423219431865e-06,
      "loss": 0.1157,
      "step": 4810
    },
    {
      "epoch": 2.698768197088466,
      "grad_norm": 7.821745872497559,
      "learning_rate": 2.22725401399753e-06,
      "loss": 0.2075,
      "step": 4820
    },
    {
      "epoch": 2.704367301231803,
      "grad_norm": 3.8402750492095947,
      "learning_rate": 2.186084808563195e-06,
      "loss": 0.156,
      "step": 4830
    },
    {
      "epoch": 2.70996640537514,
      "grad_norm": 4.803200721740723,
      "learning_rate": 2.14491560312886e-06,
      "loss": 0.1909,
      "step": 4840
    },
    {
      "epoch": 2.715565509518477,
      "grad_norm": 4.4473981857299805,
      "learning_rate": 2.1037463976945246e-06,
      "loss": 0.1757,
      "step": 4850
    },
    {
      "epoch": 2.721164613661814,
      "grad_norm": 5.018209457397461,
      "learning_rate": 2.0625771922601897e-06,
      "loss": 0.1493,
      "step": 4860
    },
    {
      "epoch": 2.7267637178051514,
      "grad_norm": 2.688398838043213,
      "learning_rate": 2.0214079868258544e-06,
      "loss": 0.1591,
      "step": 4870
    },
    {
      "epoch": 2.732362821948488,
      "grad_norm": 9.341236114501953,
      "learning_rate": 1.9802387813915195e-06,
      "loss": 0.1402,
      "step": 4880
    },
    {
      "epoch": 2.7379619260918253,
      "grad_norm": 2.74937105178833,
      "learning_rate": 1.939069575957184e-06,
      "loss": 0.1711,
      "step": 4890
    },
    {
      "epoch": 2.7435610302351625,
      "grad_norm": 4.681183815002441,
      "learning_rate": 1.897900370522849e-06,
      "loss": 0.1552,
      "step": 4900
    },
    {
      "epoch": 2.7491601343784993,
      "grad_norm": 3.684253692626953,
      "learning_rate": 1.856731165088514e-06,
      "loss": 0.1454,
      "step": 4910
    },
    {
      "epoch": 2.7547592385218365,
      "grad_norm": 5.437953472137451,
      "learning_rate": 1.8155619596541788e-06,
      "loss": 0.1631,
      "step": 4920
    },
    {
      "epoch": 2.7603583426651737,
      "grad_norm": 2.7330591678619385,
      "learning_rate": 1.7743927542198437e-06,
      "loss": 0.216,
      "step": 4930
    },
    {
      "epoch": 2.7659574468085104,
      "grad_norm": 5.237215042114258,
      "learning_rate": 1.7332235487855088e-06,
      "loss": 0.194,
      "step": 4940
    },
    {
      "epoch": 2.7715565509518476,
      "grad_norm": 6.810741901397705,
      "learning_rate": 1.6920543433511734e-06,
      "loss": 0.2058,
      "step": 4950
    },
    {
      "epoch": 2.777155655095185,
      "grad_norm": 5.608292579650879,
      "learning_rate": 1.6508851379168383e-06,
      "loss": 0.1275,
      "step": 4960
    },
    {
      "epoch": 2.782754759238522,
      "grad_norm": 4.405477523803711,
      "learning_rate": 1.6097159324825032e-06,
      "loss": 0.2259,
      "step": 4970
    },
    {
      "epoch": 2.7883538633818588,
      "grad_norm": 5.159384250640869,
      "learning_rate": 1.568546727048168e-06,
      "loss": 0.1551,
      "step": 4980
    },
    {
      "epoch": 2.793952967525196,
      "grad_norm": 7.566722393035889,
      "learning_rate": 1.5273775216138328e-06,
      "loss": 0.1785,
      "step": 4990
    },
    {
      "epoch": 2.799552071668533,
      "grad_norm": 5.118531227111816,
      "learning_rate": 1.4862083161794979e-06,
      "loss": 0.174,
      "step": 5000
    },
    {
      "epoch": 2.8051511758118703,
      "grad_norm": 4.058474540710449,
      "learning_rate": 1.4450391107451628e-06,
      "loss": 0.1251,
      "step": 5010
    },
    {
      "epoch": 2.810750279955207,
      "grad_norm": 4.121636867523193,
      "learning_rate": 1.4038699053108276e-06,
      "loss": 0.1281,
      "step": 5020
    },
    {
      "epoch": 2.8163493840985443,
      "grad_norm": 1.0800894498825073,
      "learning_rate": 1.3627006998764925e-06,
      "loss": 0.131,
      "step": 5030
    },
    {
      "epoch": 2.8219484882418815,
      "grad_norm": 9.061544418334961,
      "learning_rate": 1.3215314944421572e-06,
      "loss": 0.1701,
      "step": 5040
    },
    {
      "epoch": 2.8275475923852182,
      "grad_norm": 8.168671607971191,
      "learning_rate": 1.2803622890078223e-06,
      "loss": 0.1474,
      "step": 5050
    },
    {
      "epoch": 2.8331466965285554,
      "grad_norm": 4.1747822761535645,
      "learning_rate": 1.2391930835734872e-06,
      "loss": 0.1702,
      "step": 5060
    },
    {
      "epoch": 2.8387458006718926,
      "grad_norm": 4.697070121765137,
      "learning_rate": 1.198023878139152e-06,
      "loss": 0.1576,
      "step": 5070
    },
    {
      "epoch": 2.8443449048152294,
      "grad_norm": 3.8137357234954834,
      "learning_rate": 1.156854672704817e-06,
      "loss": 0.1754,
      "step": 5080
    },
    {
      "epoch": 2.8499440089585666,
      "grad_norm": 7.1807379722595215,
      "learning_rate": 1.1156854672704816e-06,
      "loss": 0.1541,
      "step": 5090
    },
    {
      "epoch": 2.855543113101904,
      "grad_norm": 3.6971170902252197,
      "learning_rate": 1.0745162618361467e-06,
      "loss": 0.2355,
      "step": 5100
    },
    {
      "epoch": 2.8611422172452405,
      "grad_norm": 3.4881582260131836,
      "learning_rate": 1.0333470564018116e-06,
      "loss": 0.1756,
      "step": 5110
    },
    {
      "epoch": 2.8667413213885777,
      "grad_norm": 4.853821754455566,
      "learning_rate": 9.921778509674763e-07,
      "loss": 0.1577,
      "step": 5120
    },
    {
      "epoch": 2.872340425531915,
      "grad_norm": 3.465622901916504,
      "learning_rate": 9.510086455331413e-07,
      "loss": 0.1552,
      "step": 5130
    },
    {
      "epoch": 2.8779395296752517,
      "grad_norm": 8.596128463745117,
      "learning_rate": 9.098394400988062e-07,
      "loss": 0.2427,
      "step": 5140
    },
    {
      "epoch": 2.883538633818589,
      "grad_norm": 6.967222690582275,
      "learning_rate": 8.686702346644709e-07,
      "loss": 0.133,
      "step": 5150
    },
    {
      "epoch": 2.889137737961926,
      "grad_norm": 4.920132160186768,
      "learning_rate": 8.275010292301359e-07,
      "loss": 0.1622,
      "step": 5160
    },
    {
      "epoch": 2.8947368421052633,
      "grad_norm": 2.6807262897491455,
      "learning_rate": 7.863318237958008e-07,
      "loss": 0.1877,
      "step": 5170
    },
    {
      "epoch": 2.9003359462486005,
      "grad_norm": 3.3860881328582764,
      "learning_rate": 7.451626183614657e-07,
      "loss": 0.1444,
      "step": 5180
    },
    {
      "epoch": 2.9059350503919372,
      "grad_norm": 4.6848859786987305,
      "learning_rate": 7.039934129271306e-07,
      "loss": 0.15,
      "step": 5190
    },
    {
      "epoch": 2.9115341545352744,
      "grad_norm": 9.350591659545898,
      "learning_rate": 6.628242074927954e-07,
      "loss": 0.145,
      "step": 5200
    },
    {
      "epoch": 2.9171332586786116,
      "grad_norm": 8.792459487915039,
      "learning_rate": 6.216550020584604e-07,
      "loss": 0.1548,
      "step": 5210
    },
    {
      "epoch": 2.9227323628219484,
      "grad_norm": 5.91477632522583,
      "learning_rate": 5.804857966241252e-07,
      "loss": 0.1705,
      "step": 5220
    },
    {
      "epoch": 2.9283314669652856,
      "grad_norm": 4.833531379699707,
      "learning_rate": 5.393165911897901e-07,
      "loss": 0.1875,
      "step": 5230
    },
    {
      "epoch": 2.9339305711086228,
      "grad_norm": 2.397243022918701,
      "learning_rate": 4.981473857554549e-07,
      "loss": 0.1422,
      "step": 5240
    },
    {
      "epoch": 2.9395296752519595,
      "grad_norm": 5.911332130432129,
      "learning_rate": 4.5697818032111985e-07,
      "loss": 0.1781,
      "step": 5250
    },
    {
      "epoch": 2.9451287793952967,
      "grad_norm": 4.441394805908203,
      "learning_rate": 4.1580897488678473e-07,
      "loss": 0.1815,
      "step": 5260
    },
    {
      "epoch": 2.950727883538634,
      "grad_norm": 4.004319190979004,
      "learning_rate": 3.7463976945244956e-07,
      "loss": 0.1654,
      "step": 5270
    },
    {
      "epoch": 2.9563269876819707,
      "grad_norm": 8.339011192321777,
      "learning_rate": 3.334705640181145e-07,
      "loss": 0.2316,
      "step": 5280
    },
    {
      "epoch": 2.961926091825308,
      "grad_norm": 5.830781936645508,
      "learning_rate": 2.9230135858377934e-07,
      "loss": 0.1963,
      "step": 5290
    },
    {
      "epoch": 2.967525195968645,
      "grad_norm": 4.342329978942871,
      "learning_rate": 2.511321531494442e-07,
      "loss": 0.1735,
      "step": 5300
    },
    {
      "epoch": 2.973124300111982,
      "grad_norm": 2.3030648231506348,
      "learning_rate": 2.099629477151091e-07,
      "loss": 0.1178,
      "step": 5310
    },
    {
      "epoch": 2.978723404255319,
      "grad_norm": 7.430139541625977,
      "learning_rate": 1.6879374228077402e-07,
      "loss": 0.1555,
      "step": 5320
    },
    {
      "epoch": 2.984322508398656,
      "grad_norm": 2.801225185394287,
      "learning_rate": 1.2762453684643888e-07,
      "loss": 0.1406,
      "step": 5330
    },
    {
      "epoch": 2.9899216125419934,
      "grad_norm": 4.37490701675415,
      "learning_rate": 8.645533141210376e-08,
      "loss": 0.2014,
      "step": 5340
    },
    {
      "epoch": 2.9955207166853306,
      "grad_norm": 3.484687566757202,
      "learning_rate": 4.5286125977768634e-08,
      "loss": 0.2344,
      "step": 5350
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9197928331466966,
      "eval_f1": 0.9199727744301376,
      "eval_loss": 0.23093931376934052,
      "eval_precision": 0.921202900986193,
      "eval_recall": 0.9197928331466966,
      "eval_runtime": 515.5945,
      "eval_samples_per_second": 27.712,
      "eval_steps_per_second": 0.434,
      "step": 5358
    }
  ],
  "logging_steps": 10,
  "max_steps": 5358,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5677033005483840.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
